{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "350d5d86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved aois_json/Vienna.geojson\n",
      "Saved aois_json/Paris.geojson\n",
      "Saved aois_json/London.geojson\n",
      "Saved aois_json/Toronto.geojson\n",
      "Saved aois_json/Vancouver.geojson\n",
      "Saved aois_json/San_Francisco.geojson\n",
      "Saved aois_json/Lisbon.geojson\n",
      "Saved aois_json/Madrid.geojson\n",
      "Saved aois_json/Barcelona.geojson\n",
      "Saved aois_json/Berlin.geojson\n",
      "Saved aois_json/Amsterdam.geojson\n",
      "Saved aois_json/Melbourne.geojson\n",
      "Saved aois_json/Sydney.geojson\n",
      "Saved aois_json/Auckland.geojson\n",
      "Saved aois_json/Seattle.geojson\n",
      "All 15 city AOIs saved as separate GeoJSON files in 'aois_json' folder.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import shapely.geometry\n",
    "from shapely.ops import transform\n",
    "import pyproj\n",
    "\n",
    "# Make folder if it doesn't exist\n",
    "folder = \"aois_json\"\n",
    "os.makedirs(folder, exist_ok=True)\n",
    "\n",
    "# City centers: (lon, lat)\n",
    "cities = {\n",
    "    \"Vienna\": (16.3738, 48.2082),\n",
    "    \"Paris\": (2.3522, 48.8566),\n",
    "    \"London\": (-0.1276, 51.5074),\n",
    "    \"Toronto\": (-79.3832, 43.6532),\n",
    "    \"Vancouver\": (-123.1207, 49.2827),\n",
    "    \"San_Francisco\": (-122.4194, 37.7749),\n",
    "    \"Lisbon\": (-9.1393, 38.7223),\n",
    "    \"Madrid\": (-3.7038, 40.4168),\n",
    "    \"Barcelona\": (2.1734, 41.3851),\n",
    "    \"Berlin\": (13.4050, 52.5200),\n",
    "    \"Amsterdam\": (4.9041, 52.3676),\n",
    "    \"Melbourne\": (144.9631, -37.8136),\n",
    "    \"Sydney\": (151.2093, -33.8688),\n",
    "    \"Auckland\": (174.7633, -36.8485),\n",
    "    \"Seattle\": (-122.3321, 47.6062)\n",
    "}\n",
    "\n",
    "# AOI size in meters (~5.12 km to match 512x512 pixels at 10 m)\n",
    "size_m = 512 * 10  \n",
    "\n",
    "def create_square_aoi(center_lon, center_lat, size_m):\n",
    "    \"\"\"\n",
    "    Create a square AOI of size_m x size_m around the city center.\n",
    "    \"\"\"\n",
    "    utm_zone = int((center_lon + 180) / 6) + 1\n",
    "    utm = pyproj.Proj(proj='utm', zone=utm_zone, ellps='WGS84')\n",
    "    wgs84 = pyproj.Proj(proj='latlong', datum='WGS84')\n",
    "\n",
    "    project_to_utm = pyproj.Transformer.from_proj(wgs84, utm, always_xy=True).transform\n",
    "    project_to_wgs = pyproj.Transformer.from_proj(utm, wgs84, always_xy=True).transform\n",
    "\n",
    "    point = shapely.geometry.Point(center_lon, center_lat)\n",
    "    point_utm = transform(project_to_utm, point)\n",
    "\n",
    "    half_size = size_m / 2\n",
    "    square_utm = shapely.geometry.box(\n",
    "        point_utm.x - half_size,\n",
    "        point_utm.y - half_size,\n",
    "        point_utm.x + half_size,\n",
    "        point_utm.y + half_size\n",
    "    )\n",
    "\n",
    "    square_wgs = transform(project_to_wgs, square_utm)\n",
    "    return square_wgs\n",
    "\n",
    "# Generate one JSON per city\n",
    "for city, (lon, lat) in cities.items():\n",
    "    square = create_square_aoi(lon, lat, size_m)\n",
    "    polygon_coords = [list(coord) for coord in square.exterior.coords]\n",
    "    geojson = {\n",
    "        \"type\": \"FeatureCollection\",\n",
    "        \"features\": [\n",
    "            {\n",
    "                \"type\": \"Feature\",\n",
    "                \"properties\": {\"city\": city},\n",
    "                \"geometry\": {\"type\": \"Polygon\", \"coordinates\": [polygon_coords]}\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "    filepath = os.path.join(folder, f\"{city.replace(' ', '_')}.geojson\")\n",
    "    with open(filepath, \"w\") as f:\n",
    "        json.dump(geojson, f, indent=2)\n",
    "    print(f\"Saved {filepath}\")\n",
    "\n",
    "print(\"All 15 city AOIs saved as separate GeoJSON files in 'aois_json' folder.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a699d1a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "SENTINEL-2 MULTI-MONTH PREPROCESSING PIPELINE\n",
      "============================================================\n",
      "\n",
      "Base path: sentinel_data\n",
      "Cities: London, Melbourne, Paris, Seattle, San_Francisco\n",
      "Months: April, August, November\n",
      "Bands: B02, B03, B04, B08\n",
      "Output folder: processed_stacks\n",
      "\n",
      "============================================================\n",
      "PROCESSING CITY: London\n",
      "============================================================\n",
      "\n",
      "=== Processing London - April ===\n",
      "  Loading bands from: London-April-10m\n",
      "      ✓ Found B02: T30UXC_20250402T105619_B02_10m.jp2\n",
      "    ✓ Loading B02: T30UXC_20250402T105619_B02_10m.jp2\n",
      "      ✓ Found B03: T30UXC_20250402T105619_B03_10m.jp2\n",
      "    ✓ Loading B03: T30UXC_20250402T105619_B03_10m.jp2\n",
      "      ✓ Found B04: T30UXC_20250402T105619_B04_10m.jp2\n",
      "    ✓ Loading B04: T30UXC_20250402T105619_B04_10m.jp2\n",
      "      ✓ Found B08: T30UXC_20250402T105619_B08_10m.jp2\n",
      "    ✓ Loading B08: T30UXC_20250402T105619_B08_10m.jp2\n",
      "  ✓ Loaded 4 bands, shape: (4, 10980, 10980)\n",
      "\n",
      "=== Processing London - August ===\n",
      "  Loading bands from: London-August-10m\n",
      "      ✓ Found B02: T30UXC_20250825T105641_B02_10m.jp2\n",
      "    ✓ Loading B02: T30UXC_20250825T105641_B02_10m.jp2\n",
      "      ✓ Found B03: T30UXC_20250825T105641_B03_10m.jp2\n",
      "    ✓ Loading B03: T30UXC_20250825T105641_B03_10m.jp2\n",
      "      ✓ Found B04: T30UXC_20250825T105641_B04_10m.jp2\n",
      "    ✓ Loading B04: T30UXC_20250825T105641_B04_10m.jp2\n",
      "      ✓ Found B08: T30UXC_20250825T105641_B08_10m.jp2\n",
      "    ✓ Loading B08: T30UXC_20250825T105641_B08_10m.jp2\n",
      "  ✓ Loaded 4 bands, shape: (4, 10980, 10980)\n",
      "\n",
      "=== Processing London - November ===\n",
      "  Loading bands from: London-November-10m\n",
      "      ✓ Found B02: T30UXC_20251121T111259_B02_10m.jp2\n",
      "    ✓ Loading B02: T30UXC_20251121T111259_B02_10m.jp2\n",
      "      ✓ Found B03: T30UXC_20251121T111259_B03_10m.jp2\n",
      "    ✓ Loading B03: T30UXC_20251121T111259_B03_10m.jp2\n",
      "      ✓ Found B04: T30UXC_20251121T111259_B04_10m.jp2\n",
      "    ✓ Loading B04: T30UXC_20251121T111259_B04_10m.jp2\n",
      "      ✓ Found B08: T30UXC_20251121T111259_B08_10m.jp2\n",
      "    ✓ Loading B08: T30UXC_20251121T111259_B08_10m.jp2\n",
      "  ✓ Loaded 4 bands, shape: (4, 10980, 10980)\n",
      "\n",
      "============================================================\n",
      "CREATING MULTI-MONTH STACK\n",
      "============================================================\n",
      "  Final stack shape: (12, 10980, 10980)\n",
      "  Total bands: 12 (3 months × 4 bands)\n",
      "\n",
      "  Saving to: processed_stacks/London_MultiMonth_stack.tif\n",
      "  ✓ Stack saved successfully!\n",
      "\n",
      "  Stack Statistics:\n",
      "    Min: 0.00\n",
      "    Max: 19296.00\n",
      "    Mean: 1051.51\n",
      "    NaN pixels: 0\n",
      "\n",
      "============================================================\n",
      "PROCESSING CITY: Melbourne\n",
      "============================================================\n",
      "\n",
      "=== Processing Melbourne - April ===\n",
      "  Loading bands from: Melbourne-April-10m\n",
      "      ✓ Found B02: T55HCU_20250421T001109_B02_10m.jp2\n",
      "    ✓ Loading B02: T55HCU_20250421T001109_B02_10m.jp2\n",
      "      ✓ Found B03: T55HCU_20250421T001109_B03_10m.jp2\n",
      "    ✓ Loading B03: T55HCU_20250421T001109_B03_10m.jp2\n",
      "      ✓ Found B04: T55HCU_20250421T001109_B04_10m.jp2\n",
      "    ✓ Loading B04: T55HCU_20250421T001109_B04_10m.jp2\n",
      "      ✓ Found B08: T55HCU_20250421T001109_B08_10m.jp2\n",
      "    ✓ Loading B08: T55HCU_20250421T001109_B08_10m.jp2\n",
      "  ✓ Loaded 4 bands, shape: (4, 10980, 10980)\n",
      "\n",
      "=== Processing Melbourne - August ===\n",
      "  Loading bands from: Melbourne-August-10m\n",
      "      ✓ Found B02: T55HCU_20250129T002121_B02_10m.jp2\n",
      "    ✓ Loading B02: T55HCU_20250129T002121_B02_10m.jp2\n",
      "      ✓ Found B03: T55HCU_20250129T002121_B03_10m.jp2\n",
      "    ✓ Loading B03: T55HCU_20250129T002121_B03_10m.jp2\n",
      "      ✓ Found B04: T55HCU_20250129T002121_B04_10m.jp2\n",
      "    ✓ Loading B04: T55HCU_20250129T002121_B04_10m.jp2\n",
      "      ✓ Found B08: T55HCU_20250129T002121_B08_10m.jp2\n",
      "    ✓ Loading B08: T55HCU_20250129T002121_B08_10m.jp2\n",
      "  ✓ Loaded 4 bands, shape: (4, 10980, 10980)\n",
      "\n",
      "=== Processing Melbourne - November ===\n",
      "  Loading bands from: Melbourne-November-10m\n",
      "      ✓ Found B02: T55HCU_20251124T001251_B02_10m.jp2\n",
      "    ✓ Loading B02: T55HCU_20251124T001251_B02_10m.jp2\n",
      "      ✓ Found B03: T55HCU_20251124T001251_B03_10m.jp2\n",
      "    ✓ Loading B03: T55HCU_20251124T001251_B03_10m.jp2\n",
      "      ✓ Found B04: T55HCU_20251124T001251_B04_10m.jp2\n",
      "    ✓ Loading B04: T55HCU_20251124T001251_B04_10m.jp2\n",
      "      ✓ Found B08: T55HCU_20251124T001251_B08_10m.jp2\n",
      "    ✓ Loading B08: T55HCU_20251124T001251_B08_10m.jp2\n",
      "  ✓ Loaded 4 bands, shape: (4, 10980, 10980)\n",
      "\n",
      "============================================================\n",
      "CREATING MULTI-MONTH STACK\n",
      "============================================================\n",
      "  Final stack shape: (12, 10980, 10980)\n",
      "  Total bands: 12 (3 months × 4 bands)\n",
      "\n",
      "  Saving to: processed_stacks/Melbourne_MultiMonth_stack.tif\n",
      "  ✓ Stack saved successfully!\n",
      "\n",
      "  Stack Statistics:\n",
      "    Min: 0.00\n",
      "    Max: 19968.00\n",
      "    Mean: 1908.08\n",
      "    NaN pixels: 0\n",
      "\n",
      "============================================================\n",
      "PROCESSING CITY: Paris\n",
      "============================================================\n",
      "\n",
      "=== Processing Paris - April ===\n",
      "  Loading bands from: Paris-April-10m\n",
      "      ✓ Found B02: T31UDQ_20250429T105701_B02_10m.jp2\n",
      "    ✓ Loading B02: T31UDQ_20250429T105701_B02_10m.jp2\n",
      "      ✓ Found B03: T31UDQ_20250429T105701_B03_10m.jp2\n",
      "    ✓ Loading B03: T31UDQ_20250429T105701_B03_10m.jp2\n",
      "      ✓ Found B04: T31UDQ_20250429T105701_B04_10m.jp2\n",
      "    ✓ Loading B04: T31UDQ_20250429T105701_B04_10m.jp2\n",
      "      ✓ Found B08: T31UDQ_20250429T105701_B08_10m.jp2\n",
      "    ✓ Loading B08: T31UDQ_20250429T105701_B08_10m.jp2\n",
      "  ✓ Loaded 4 bands, shape: (4, 10980, 10980)\n",
      "\n",
      "=== Processing Paris - August ===\n",
      "  Loading bands from: Paris-August-10m\n",
      "      ✓ Found B02: T31UDQ_20250817T105651_B02_10m.jp2\n",
      "    ✓ Loading B02: T31UDQ_20250817T105651_B02_10m.jp2\n",
      "      ✓ Found B03: T31UDQ_20250817T105651_B03_10m.jp2\n",
      "    ✓ Loading B03: T31UDQ_20250817T105651_B03_10m.jp2\n",
      "      ✓ Found B04: T31UDQ_20250817T105651_B04_10m.jp2\n",
      "    ✓ Loading B04: T31UDQ_20250817T105651_B04_10m.jp2\n",
      "      ✓ Found B08: T31UDQ_20250817T105651_B08_10m.jp2\n",
      "    ✓ Loading B08: T31UDQ_20250817T105651_B08_10m.jp2\n",
      "  ✓ Loaded 4 bands, shape: (4, 10980, 10980)\n",
      "\n",
      "=== Processing Paris - November ===\n",
      "  Loading bands from: Paris-November-10m\n",
      "      ✓ Found B02: T31UDQ_20251230T105451_B02_10m.jp2\n",
      "    ✓ Loading B02: T31UDQ_20251230T105451_B02_10m.jp2\n",
      "      ✓ Found B03: T31UDQ_20251230T105451_B03_10m.jp2\n",
      "    ✓ Loading B03: T31UDQ_20251230T105451_B03_10m.jp2\n",
      "      ✓ Found B04: T31UDQ_20251230T105451_B04_10m.jp2\n",
      "    ✓ Loading B04: T31UDQ_20251230T105451_B04_10m.jp2\n",
      "      ✓ Found B08: T31UDQ_20251230T105451_B08_10m.jp2\n",
      "    ✓ Loading B08: T31UDQ_20251230T105451_B08_10m.jp2\n",
      "  ✓ Loaded 4 bands, shape: (4, 10980, 10980)\n",
      "\n",
      "============================================================\n",
      "CREATING MULTI-MONTH STACK\n",
      "============================================================\n",
      "  Final stack shape: (12, 10980, 10980)\n",
      "  Total bands: 12 (3 months × 4 bands)\n",
      "\n",
      "  Saving to: processed_stacks/Paris_MultiMonth_stack.tif\n",
      "  ✓ Stack saved successfully!\n",
      "\n",
      "  Stack Statistics:\n",
      "    Min: 0.00\n",
      "    Max: 19104.00\n",
      "    Mean: 1814.25\n",
      "    NaN pixels: 0\n",
      "\n",
      "============================================================\n",
      "PROCESSING CITY: Seattle\n",
      "============================================================\n",
      "\n",
      "=== Processing Seattle - April ===\n",
      "  Loading bands from: Seattle-April-10m\n",
      "      ✓ Found B02: T10TET_20250424T190941_B02_10m.jp2\n",
      "    ✓ Loading B02: T10TET_20250424T190941_B02_10m.jp2\n",
      "      ✓ Found B03: T10TET_20250424T190941_B03_10m.jp2\n",
      "    ✓ Loading B03: T10TET_20250424T190941_B03_10m.jp2\n",
      "      ✓ Found B04: T10TET_20250424T190941_B04_10m.jp2\n",
      "    ✓ Loading B04: T10TET_20250424T190941_B04_10m.jp2\n",
      "      ✓ Found B08: T10TET_20250424T190941_B08_10m.jp2\n",
      "    ✓ Loading B08: T10TET_20250424T190941_B08_10m.jp2\n",
      "  ✓ Loaded 4 bands, shape: (4, 10980, 10980)\n",
      "\n",
      "=== Processing Seattle - August ===\n",
      "  Loading bands from: Seattle-August-10m\n",
      "      ✓ Found B02: T10TET_20250822T190931_B02_10m.jp2\n",
      "    ✓ Loading B02: T10TET_20250822T190931_B02_10m.jp2\n",
      "      ✓ Found B03: T10TET_20250822T190931_B03_10m.jp2\n",
      "    ✓ Loading B03: T10TET_20250822T190931_B03_10m.jp2\n",
      "      ✓ Found B04: T10TET_20250822T190931_B04_10m.jp2\n",
      "    ✓ Loading B04: T10TET_20250822T190931_B04_10m.jp2\n",
      "      ✓ Found B08: T10TET_20250822T190931_B08_10m.jp2\n",
      "    ✓ Loading B08: T10TET_20250822T190931_B08_10m.jp2\n",
      "  ✓ Loaded 4 bands, shape: (4, 10980, 10980)\n",
      "\n",
      "=== Processing Seattle - November ===\n",
      "  Loading bands from: Seattle-November-10m\n",
      "      ✓ Found B02: T10TET_20251130T191801_B02_10m.jp2\n",
      "    ✓ Loading B02: T10TET_20251130T191801_B02_10m.jp2\n",
      "      ✓ Found B03: T10TET_20251130T191801_B03_10m.jp2\n",
      "    ✓ Loading B03: T10TET_20251130T191801_B03_10m.jp2\n",
      "      ✓ Found B04: T10TET_20251130T191801_B04_10m.jp2\n",
      "    ✓ Loading B04: T10TET_20251130T191801_B04_10m.jp2\n",
      "      ✓ Found B08: T10TET_20251130T191801_B08_10m.jp2\n",
      "    ✓ Loading B08: T10TET_20251130T191801_B08_10m.jp2\n",
      "  ✓ Loaded 4 bands, shape: (4, 10980, 10980)\n",
      "\n",
      "============================================================\n",
      "CREATING MULTI-MONTH STACK\n",
      "============================================================\n",
      "  Final stack shape: (12, 10980, 10980)\n",
      "  Total bands: 12 (3 months × 4 bands)\n",
      "\n",
      "  Saving to: processed_stacks/Seattle_MultiMonth_stack.tif\n",
      "  ✓ Stack saved successfully!\n",
      "\n",
      "  Stack Statistics:\n",
      "    Min: 0.00\n",
      "    Max: 20736.00\n",
      "    Mean: 1824.77\n",
      "    NaN pixels: 0\n",
      "\n",
      "============================================================\n",
      "PROCESSING CITY: San_Francisco\n",
      "============================================================\n",
      "\n",
      "=== Processing San_Francisco - April ===\n",
      "  Loading bands from: San_Francisco-April-10m\n",
      "      ✓ Found B02: T10SEG_20250408T184941_B02_10m.jp2\n",
      "    ✓ Loading B02: T10SEG_20250408T184941_B02_10m.jp2\n",
      "      ✓ Found B03: T10SEG_20250408T184941_B03_10m.jp2\n",
      "    ✓ Loading B03: T10SEG_20250408T184941_B03_10m.jp2\n",
      "      ✓ Found B04: T10SEG_20250408T184941_B04_10m.jp2\n",
      "    ✓ Loading B04: T10SEG_20250408T184941_B04_10m.jp2\n",
      "      ✓ Found B08: T10SEG_20250408T184941_B08_10m.jp2\n",
      "    ✓ Loading B08: T10SEG_20250408T184941_B08_10m.jp2\n",
      "  ✓ Loaded 4 bands, shape: (4, 10980, 10980)\n",
      "\n",
      "=== Processing San_Francisco - August ===\n",
      "  Loading bands from: San_Francisco-August-10m\n",
      "      ✓ Found B02: T10SEG_20250831T184919_B02_10m.jp2\n",
      "    ✓ Loading B02: T10SEG_20250831T184919_B02_10m.jp2\n",
      "      ✓ Found B03: T10SEG_20250831T184919_B03_10m.jp2\n",
      "    ✓ Loading B03: T10SEG_20250831T184919_B03_10m.jp2\n",
      "      ✓ Found B04: T10SEG_20250831T184919_B04_10m.jp2\n",
      "    ✓ Loading B04: T10SEG_20250831T184919_B04_10m.jp2\n",
      "      ✓ Found B08: T10SEG_20250831T184919_B08_10m.jp2\n",
      "    ✓ Loading B08: T10SEG_20250831T184919_B08_10m.jp2\n",
      "  ✓ Loaded 4 bands, shape: (4, 10980, 10980)\n",
      "\n",
      "=== Processing San_Francisco - November ===\n",
      "  Loading bands from: San_Francisco-November-10m\n",
      "      ✓ Found B02: T10SEG_20251126T185831_B02_10m.jp2\n",
      "    ✓ Loading B02: T10SEG_20251126T185831_B02_10m.jp2\n",
      "      ✓ Found B03: T10SEG_20251126T185831_B03_10m.jp2\n",
      "    ✓ Loading B03: T10SEG_20251126T185831_B03_10m.jp2\n",
      "      ✓ Found B04: T10SEG_20251126T185831_B04_10m.jp2\n",
      "    ✓ Loading B04: T10SEG_20251126T185831_B04_10m.jp2\n",
      "      ✓ Found B08: T10SEG_20251126T185831_B08_10m.jp2\n",
      "    ✓ Loading B08: T10SEG_20251126T185831_B08_10m.jp2\n",
      "  ✓ Loaded 4 bands, shape: (4, 10980, 10980)\n",
      "\n",
      "============================================================\n",
      "CREATING MULTI-MONTH STACK\n",
      "============================================================\n",
      "  Final stack shape: (12, 10980, 10980)\n",
      "  Total bands: 12 (3 months × 4 bands)\n",
      "\n",
      "  Saving to: processed_stacks/San_Francisco_MultiMonth_stack.tif\n",
      "  ✓ Stack saved successfully!\n",
      "\n",
      "  Stack Statistics:\n",
      "    Min: 0.00\n",
      "    Max: 19696.00\n",
      "    Mean: 1626.06\n",
      "    NaN pixels: 0\n",
      "\n",
      "\n",
      "============================================================\n",
      "PROCESSING SUMMARY\n",
      "============================================================\n",
      "\n",
      "✓ Successfully processed: 5 cities\n",
      "  - London\n",
      "  - Melbourne\n",
      "  - Paris\n",
      "  - Seattle\n",
      "  - San_Francisco\n",
      "\n",
      "============================================================\n",
      "PIPELINE COMPLETE!\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Sentinel-2 Multi-Month Data Preprocessing Pipeline\n",
    "Processes Sentinel-2 data for multiple cities and creates multi-temporal stacks\n",
    "\"\"\"\n",
    "\n",
    "import rasterio\n",
    "import numpy as np\n",
    "import os\n",
    "from pathlib import Path\n",
    "from rasterio.warp import calculate_default_transform, reproject, Resampling\n",
    "from rasterio.merge import merge\n",
    "\n",
    "# ============================================================\n",
    "# CONFIGURATION\n",
    "# ============================================================\n",
    "\n",
    "BASE_PATH = \"sentinel_data\"\n",
    "CITIES = [\"London\", \"Melbourne\", \"Paris\", \"Seattle\", \"San_Francisco\"]\n",
    "\n",
    "MONTHS = {\n",
    "    \"April\": \"April-10m\",\n",
    "    \"August\": \"August-10m\", \n",
    "    \"November\": \"November-10m\"\n",
    "}\n",
    "\n",
    "BANDS_10M = [\"B02\", \"B03\", \"B04\", \"B08\"]\n",
    "OUTPUT_FOLDER = \"processed_stacks\"\n",
    "os.makedirs(OUTPUT_FOLDER, exist_ok=True)\n",
    "\n",
    "# ============================================================\n",
    "# HELPER FUNCTIONS\n",
    "# ============================================================\n",
    "\n",
    "def find_band_file(folder_path, band_name):\n",
    "    folder = Path(folder_path)\n",
    "    \n",
    "    if not folder.exists():\n",
    "        print(f\"      ERROR: Folder does not exist: {folder}\")\n",
    "        return None\n",
    "    \n",
    "    patterns = [\n",
    "        f\"*_{band_name}_10m.jp2\",\n",
    "        f\"*_{band_name}.jp2\",\n",
    "        f\"**/*_{band_name}_10m.jp2\",\n",
    "        f\"**/*_{band_name}.jp2\",\n",
    "        f\"**/IMG_DATA/**/*{band_name}*.jp2\"\n",
    "    ]\n",
    "    \n",
    "    for pattern in patterns:\n",
    "        matches = list(folder.glob(pattern))\n",
    "        if matches:\n",
    "            print(f\"      ✓ Found {band_name}: {matches[0].name}\")\n",
    "            return str(matches[0])\n",
    "    \n",
    "    all_jp2_files = list(folder.rglob(\"*.jp2\"))\n",
    "    for file in all_jp2_files:\n",
    "        if band_name in file.name:\n",
    "            print(f\"      ✓ Found {band_name} (fuzzy match): {file.name}\")\n",
    "            return str(file)\n",
    "    \n",
    "    print(f\"      ✗ Could not find {band_name}\")\n",
    "    print(f\"      DEBUG: Listing .jp2 files in {folder.name}:\")\n",
    "    if all_jp2_files:\n",
    "        for f in all_jp2_files[:8]:\n",
    "            print(f\"        - {f.name}\")\n",
    "        if len(all_jp2_files) > 8:\n",
    "            print(f\"        ... and {len(all_jp2_files) - 8} more files\")\n",
    "    else:\n",
    "        print(f\"        - No .jp2 files found in {folder} or subdirectories!\")\n",
    "        all_files = list(folder.rglob(\"*\"))\n",
    "        print(f\"        - Total files/folders: {len(all_files)}\")\n",
    "    \n",
    "    return None\n",
    "\n",
    "\n",
    "def load_and_stack_bands(folder_path, bands):\n",
    "    band_arrays = []\n",
    "    profile = None\n",
    "    \n",
    "    print(f\"  Loading bands from: {Path(folder_path).name}\")\n",
    "    \n",
    "    for band in bands:\n",
    "        band_file = find_band_file(folder_path, band)\n",
    "        \n",
    "        if band_file is None:\n",
    "            print(f\"    WARNING: {band} not found, skipping...\")\n",
    "            continue\n",
    "            \n",
    "        print(f\"    ✓ Loading {band}: {Path(band_file).name}\")\n",
    "        \n",
    "        with rasterio.open(band_file) as src:\n",
    "            band_data = src.read(1)\n",
    "            band_arrays.append(band_data)\n",
    "            \n",
    "            if profile is None:\n",
    "                profile = src.profile.copy()\n",
    "    \n",
    "    if not band_arrays:\n",
    "        return None, None\n",
    "    \n",
    "    stacked = np.stack(band_arrays, axis=0)\n",
    "    \n",
    "    profile.update(\n",
    "        count=len(band_arrays), \n",
    "        dtype='uint16',\n",
    "        driver='GTiff',\n",
    "        compress='lzw'\n",
    "    )\n",
    "    \n",
    "    return stacked, profile\n",
    "\n",
    "\n",
    "def create_multimonth_stack(city, base_path, months, bands):\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"PROCESSING CITY: {city}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    all_month_data = []\n",
    "    final_profile = None\n",
    "    \n",
    "    for month_name, month_suffix in months.items():\n",
    "        folder_path = f\"{base_path}/{city}/{city}-{month_suffix}\"\n",
    "        \n",
    "        print(f\"\\n=== Processing {city} - {month_name} ===\")\n",
    "        \n",
    "        if not os.path.exists(folder_path):\n",
    "            print(f\"  WARNING: Folder not found: {folder_path}\")\n",
    "            print(f\"  Skipping {month_name} for {city}...\")\n",
    "            continue\n",
    "        \n",
    "        month_stack, profile = load_and_stack_bands(folder_path, bands)\n",
    "        \n",
    "        if month_stack is None:\n",
    "            print(f\"  WARNING: No bands loaded for {month_name}, skipping...\")\n",
    "            continue\n",
    "        \n",
    "        print(f\"  ✓ Loaded {month_stack.shape[0]} bands, shape: {month_stack.shape}\")\n",
    "        \n",
    "        all_month_data.append(month_stack)\n",
    "        \n",
    "        if final_profile is None:\n",
    "            final_profile = profile\n",
    "    \n",
    "    if not all_month_data:\n",
    "        print(f\"\\n  ERROR: No data loaded for {city}, skipping stack creation\")\n",
    "        return None\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"CREATING MULTI-MONTH STACK\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    full_stack = np.concatenate(all_month_data, axis=0)\n",
    "    \n",
    "    if full_stack.dtype != np.uint16:\n",
    "        print(f\"  Converting from {full_stack.dtype} to uint16...\")\n",
    "        full_stack = full_stack.astype(np.uint16)\n",
    "    \n",
    "    print(f\"  Final stack shape: {full_stack.shape}\")\n",
    "    print(f\"  Total bands: {full_stack.shape[0]} ({len(all_month_data)} months × {len(bands)} bands)\")\n",
    "    \n",
    "    final_profile.update(\n",
    "        count=full_stack.shape[0],\n",
    "        dtype='uint16'\n",
    "    )\n",
    "    \n",
    "    output_path = f\"{OUTPUT_FOLDER}/{city}_MultiMonth_stack.tif\"\n",
    "    \n",
    "    print(f\"\\n  Saving to: {output_path}\")\n",
    "    \n",
    "    with rasterio.open(output_path, 'w', **final_profile) as dst:\n",
    "        dst.write(full_stack)\n",
    "    \n",
    "    print(f\"  ✓ Stack saved successfully!\")\n",
    "    \n",
    "    print(f\"\\n  Stack Statistics:\")\n",
    "    print(f\"    Min: {np.nanmin(full_stack):.2f}\")\n",
    "    print(f\"    Max: {np.nanmax(full_stack):.2f}\")\n",
    "    print(f\"    Mean: {np.nanmean(full_stack):.2f}\")\n",
    "    print(f\"    NaN pixels: {np.isnan(full_stack).sum():,}\")\n",
    "    \n",
    "    return output_path\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# MAIN PROCESSING LOOP\n",
    "# ============================================================\n",
    "\n",
    "def main():\n",
    "    print(\"=\"*60)\n",
    "    print(\"SENTINEL-2 MULTI-MONTH PREPROCESSING PIPELINE\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"\\nBase path: {BASE_PATH}\")\n",
    "    print(f\"Cities: {', '.join(CITIES)}\")\n",
    "    print(f\"Months: {', '.join(MONTHS.keys())}\")\n",
    "    print(f\"Bands: {', '.join(BANDS_10M)}\")\n",
    "    print(f\"Output folder: {OUTPUT_FOLDER}\")\n",
    "    \n",
    "    successful_cities = []\n",
    "    failed_cities = []\n",
    "    \n",
    "    for city in CITIES:\n",
    "        try:\n",
    "            output_path = create_multimonth_stack(\n",
    "                city=city,\n",
    "                base_path=BASE_PATH,\n",
    "                months=MONTHS,\n",
    "                bands=BANDS_10M\n",
    "            )\n",
    "            \n",
    "            if output_path:\n",
    "                successful_cities.append(city)\n",
    "            else:\n",
    "                failed_cities.append(city)\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"\\n  ERROR processing {city}: {str(e)}\")\n",
    "            failed_cities.append(city)\n",
    "    \n",
    "    print(f\"\\n\\n{'='*60}\")\n",
    "    print(\"PROCESSING SUMMARY\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"\\n✓ Successfully processed: {len(successful_cities)} cities\")\n",
    "    for city in successful_cities:\n",
    "        print(f\"  - {city}\")\n",
    "    \n",
    "    if failed_cities:\n",
    "        print(f\"\\n✗ Failed: {len(failed_cities)} cities\")\n",
    "        for city in failed_cities:\n",
    "            print(f\"  - {city}\")\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"PIPELINE COMPLETE!\")\n",
    "    print(f\"{'='*60}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9dae1175",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "PROCESSING: London\n",
      "============================================================\n",
      "Loaded AOI for London\n",
      "Fetching OSM green areas...\n",
      "✓ Saved: sentinel_data/London/London_OSM_green.geojson\n",
      "  Features: 1346\n",
      "  Total area: 17.34 km²\n",
      "\n",
      "============================================================\n",
      "PROCESSING: Melbourne\n",
      "============================================================\n",
      "Loaded AOI for Melbourne\n",
      "Fetching OSM green areas...\n",
      "✓ Saved: sentinel_data/Melbourne/Melbourne_OSM_green.geojson\n",
      "  Features: 1909\n",
      "  Total area: 14.89 km²\n",
      "\n",
      "============================================================\n",
      "PROCESSING: Paris\n",
      "============================================================\n",
      "Loaded AOI for Paris\n",
      "Fetching OSM green areas...\n",
      "✓ Saved: sentinel_data/Paris/Paris_OSM_green.geojson\n",
      "  Features: 2559\n",
      "  Total area: 7.99 km²\n",
      "\n",
      "============================================================\n",
      "PROCESSING: Seattle\n",
      "============================================================\n",
      "Loaded AOI for Seattle\n",
      "Fetching OSM green areas...\n",
      "✓ Saved: sentinel_data/Seattle/Seattle_OSM_green.geojson\n",
      "  Features: 419\n",
      "  Total area: 6.62 km²\n",
      "\n",
      "============================================================\n",
      "PROCESSING: San_Francisco\n",
      "============================================================\n",
      "Loaded AOI for San_Francisco\n",
      "Fetching OSM green areas...\n",
      "✓ Saved: sentinel_data/San_Francisco/San_Francisco_OSM_green.geojson\n",
      "  Features: 645\n",
      "  Total area: 12.62 km²\n",
      "\n",
      "============================================================\n",
      "ALL CITIES PROCESSED!\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "import osmnx as ox\n",
    "import geopandas as gpd\n",
    "import os\n",
    "\n",
    "aoi_base_folder = \"aois_json\"\n",
    "output_base_folder = \"sentinel_data\"\n",
    "cities = [\"London\", \"Melbourne\", \"Paris\", \"Seattle\", \"San_Francisco\"]\n",
    "\n",
    "tags = {\n",
    "    \"leisure\": [\"park\", \"garden\"],\n",
    "    \"landuse\": [\"forest\", \"grass\", \"meadow\", \"village_green\"],\n",
    "    \"natural\": [\"wood\", \"scrub\"]\n",
    "}\n",
    "\n",
    "for city in cities:\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"PROCESSING: {city}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    aoi_file = os.path.join(aoi_base_folder, f\"{city}.geojson\")\n",
    "    output_file = os.path.join(output_base_folder, city, f\"{city}_OSM_green.geojson\")\n",
    "    \n",
    "    if not os.path.exists(aoi_file):\n",
    "        print(f\"WARNING: AOI file not found: {aoi_file}\")\n",
    "        print(f\"Skipping {city}...\")\n",
    "        continue\n",
    "    \n",
    "    try:\n",
    "        aoi = gpd.read_file(aoi_file)\n",
    "        aoi = aoi.to_crs(\"EPSG:4326\")\n",
    "        polygon = aoi.geometry.iloc[0]\n",
    "        \n",
    "        print(f\"Loaded AOI for {city}\")\n",
    "        \n",
    "        print(f\"Fetching OSM green areas...\")\n",
    "        green_features = ox.features_from_polygon(polygon, tags)\n",
    "        \n",
    "        green_features = green_features[green_features.geometry.type.isin([\"Polygon\", \"MultiPolygon\"])]\n",
    "        \n",
    "        if len(green_features) == 0:\n",
    "            print(f\"WARNING: No green area polygons found for {city}\")\n",
    "            continue\n",
    "        \n",
    "        total_area_km2 = green_features.to_crs('EPSG:3857').area.sum() / 1e6\n",
    "        \n",
    "        os.makedirs(os.path.dirname(output_file), exist_ok=True)\n",
    "        green_features.to_file(output_file, driver=\"GeoJSON\")\n",
    "        \n",
    "        print(f\"✓ Saved: {output_file}\")\n",
    "        print(f\"  Features: {len(green_features)}\")\n",
    "        print(f\"  Total area: {total_area_km2:.2f} km²\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"ERROR processing {city}: {str(e)}\")\n",
    "        continue\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"ALL CITIES PROCESSED!\")\n",
    "print(f\"{'='*60}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9a181ac0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "PROCESSING: London\n",
      "============================================================\n",
      "Loaded stack metadata: 10980x10980 pixels\n",
      "Loaded 1346 green area polygons\n",
      "Rasterizing green areas...\n",
      "  Completed: 63528/120560400 pixels labeled as green (0.05%)\n",
      "✓ Saved: sentinel_data/London/London_OSM_labels.tif\n",
      "\n",
      "============================================================\n",
      "PROCESSING: Melbourne\n",
      "============================================================\n",
      "Loaded stack metadata: 10980x10980 pixels\n",
      "Loaded 1909 green area polygons\n",
      "Rasterizing green areas...\n",
      "  Completed: 96494/120560400 pixels labeled as green (0.08%)\n",
      "✓ Saved: sentinel_data/Melbourne/Melbourne_OSM_labels.tif\n",
      "\n",
      "============================================================\n",
      "PROCESSING: Paris\n",
      "============================================================\n",
      "Loaded stack metadata: 10980x10980 pixels\n",
      "Loaded 2559 green area polygons\n",
      "Rasterizing green areas...\n",
      "  Completed: 39572/120560400 pixels labeled as green (0.03%)\n",
      "✓ Saved: sentinel_data/Paris/Paris_OSM_labels.tif\n",
      "\n",
      "============================================================\n",
      "PROCESSING: Seattle\n",
      "============================================================\n",
      "Loaded stack metadata: 10980x10980 pixels\n",
      "Loaded 419 green area polygons\n",
      "Rasterizing green areas...\n",
      "  Completed: 34139/120560400 pixels labeled as green (0.03%)\n",
      "✓ Saved: sentinel_data/Seattle/Seattle_OSM_labels.tif\n",
      "\n",
      "============================================================\n",
      "PROCESSING: San_Francisco\n",
      "============================================================\n",
      "Loaded stack metadata: 10980x10980 pixels\n",
      "Loaded 645 green area polygons\n",
      "Rasterizing green areas...\n",
      "  Completed: 80489/120560400 pixels labeled as green (0.07%)\n",
      "✓ Saved: sentinel_data/San_Francisco/San_Francisco_OSM_labels.tif\n",
      "\n",
      "============================================================\n",
      "ALL CITIES PROCESSED!\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "import rasterio\n",
    "from rasterio.features import rasterize\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "sentinel_base_folder = \"sentinel_data\"\n",
    "stack_folder = \"processed_stacks\"        \n",
    "cities = [\"London\", \"Melbourne\", \"Paris\", \"Seattle\", \"San_Francisco\"]\n",
    "\n",
    "for city in cities:\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"PROCESSING: {city}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    stack_path = os.path.join(stack_folder, f\"{city}_MultiMonth_stack.tif\")\n",
    "    osm_path = os.path.join(sentinel_base_folder, city, f\"{city}_OSM_green.geojson\")\n",
    "    label_path = os.path.join(sentinel_base_folder, city, f\"{city}_OSM_labels.tif\")\n",
    "    \n",
    "    if not os.path.exists(stack_path):\n",
    "        print(f\"WARNING: Stack file not found: {stack_path}\")\n",
    "        print(f\"Skipping {city}...\")\n",
    "        continue\n",
    "    \n",
    "    if not os.path.exists(osm_path):\n",
    "        print(f\"WARNING: OSM green file not found: {osm_path}\")\n",
    "        print(f\"Skipping {city}...\")\n",
    "        continue\n",
    "    \n",
    "    try:\n",
    "        with rasterio.open(stack_path) as src:\n",
    "            transform = src.transform\n",
    "            out_shape = (src.height, src.width)\n",
    "            crs = src.crs\n",
    "        \n",
    "        print(f\"Loaded stack metadata: {out_shape[0]}x{out_shape[1]} pixels\")\n",
    "        \n",
    "        green_features = gpd.read_file(osm_path)\n",
    "        green_features = green_features.to_crs(crs)\n",
    "        green_features = green_features[green_features.geometry.type.isin([\"Polygon\", \"MultiPolygon\"])]\n",
    "        \n",
    "        if len(green_features) == 0:\n",
    "            print(f\"WARNING: No polygon features found for {city}\")\n",
    "            continue\n",
    "        \n",
    "        print(f\"Loaded {len(green_features)} green area polygons\")\n",
    "        print(\"Rasterizing green areas...\")\n",
    "        \n",
    "        labels = rasterize(\n",
    "            [(geom, 1) for geom in green_features.geometry],\n",
    "            out_shape=out_shape,\n",
    "            transform=transform,\n",
    "            fill=0,\n",
    "            all_touched=True,\n",
    "            dtype=\"uint8\"\n",
    "        )\n",
    "        \n",
    "        green_count = np.sum(labels == 1)\n",
    "        total_pixels = labels.size\n",
    "        print(f\"  Completed: {green_count}/{total_pixels} pixels labeled as green ({100*green_count/total_pixels:.2f}%)\")\n",
    "        \n",
    "        with rasterio.open(\n",
    "            label_path,\n",
    "            \"w\",\n",
    "            driver=\"GTiff\",\n",
    "            height=out_shape[0],\n",
    "            width=out_shape[1],\n",
    "            count=1,\n",
    "            dtype=\"uint8\",\n",
    "            crs=crs,\n",
    "            transform=transform,\n",
    "            compress=\"lzw\"\n",
    "        ) as dst:\n",
    "            dst.write(labels, 1)\n",
    "        \n",
    "        print(f\"✓ Saved: {label_path}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"ERROR processing {city}: {str(e)}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        continue\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"ALL CITIES PROCESSED!\")\n",
    "print(f\"{'='*60}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a305689b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "RANDOM FOREST TRAINING - London\n",
      "============================================================\n",
      "\n",
      "Results will be saved to: results/London_20260111_000353\n",
      "\n",
      "============================================================\n",
      "LOADING DATA\n",
      "============================================================\n",
      "✓ Loaded Sentinel-2 stack: (12, 10980, 10980)\n",
      "✓ Loaded labels: (10980, 10980)\n",
      "\n",
      "============================================================\n",
      "PREPARING DATA\n",
      "============================================================\n",
      "Original shape: 10980 × 10980 = 120,560,400 pixels\n",
      "After removing NaN: 120,560,400 pixels\n",
      "\n",
      "============================================================\n",
      "CLASS DISTRIBUTION\n",
      "============================================================\n",
      "Class 0: 120,496,872 samples (99.95%)\n",
      "Class 1: 63,528 samples (0.05%)\n",
      "\n",
      "Imbalance ratio: 1896.8:1 (non-green:green)\n",
      "\n",
      "============================================================\n",
      "TRAIN-TEST SPLIT\n",
      "============================================================\n",
      "Initial train set: 96,448,320 samples\n",
      "Initial test set: 24,112,080 samples\n",
      "\n",
      "============================================================\n",
      "SAMPLING 1.0% OF TRAINING DATA\n",
      "============================================================\n",
      "✓ Sampled 1.0% of training data: 964,483 pixels\n",
      "  Maintains class balance through stratified sampling\n",
      "Train set: 964,483 samples\n",
      "  Green: 508 (0.05%)\n",
      "Test set: 24,112,080 samples\n",
      "  Green: 12,706 (0.05%)\n",
      "\n",
      "============================================================\n",
      "TRAINING RANDOM FOREST\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 10 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  30 tasks      | elapsed:    2.1s\n",
      "[Parallel(n_jobs=-1)]: Done 180 tasks      | elapsed:   12.0s\n",
      "[Parallel(n_jobs=-1)]: Done 200 out of 200 | elapsed:   13.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✓ Training complete!\n",
      "\n",
      "============================================================\n",
      "EVALUATION\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=10)]: Using backend ThreadingBackend with 10 concurrent workers.\n",
      "[Parallel(n_jobs=10)]: Done  30 tasks      | elapsed:    3.9s\n",
      "[Parallel(n_jobs=10)]: Done 180 tasks      | elapsed:   21.5s\n",
      "[Parallel(n_jobs=10)]: Done 200 out of 200 | elapsed:   24.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Non-green       1.00      1.00      1.00  24099374\n",
      "       Green       0.15      0.03      0.06     12706\n",
      "\n",
      "    accuracy                           1.00  24112080\n",
      "   macro avg       0.57      0.52      0.53  24112080\n",
      "weighted avg       1.00      1.00      1.00  24112080\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "                Predicted\n",
      "              Non-green  Green\n",
      "Actual Non-g  24096923    2451\n",
      "       Green     12274     432\n",
      "\n",
      "------------------------------------------------------------\n",
      "SUMMARY METRICS:\n",
      "------------------------------------------------------------\n",
      "balanced_accuracy   : 0.517\n",
      "f1_green            : 0.055\n",
      "f1_macro            : 0.528\n",
      "sensitivity         : 0.034\n",
      "specificity         : 1.000\n",
      "precision_green     : 0.150\n",
      "recall_green        : 0.034\n",
      "\n",
      "============================================================\n",
      "BAND IMPORTANCE\n",
      "============================================================\n",
      "\n",
      "Top 10 Most Important Bands:\n",
      "April_B04           : 0.1893\n",
      "April_B08           : 0.1493\n",
      "April_B03           : 0.1339\n",
      "April_B02           : 0.1013\n",
      "August_B04          : 0.0912\n",
      "August_B08          : 0.0874\n",
      "August_B03          : 0.0646\n",
      "August_B02          : 0.0626\n",
      "November_B02        : 0.0324\n",
      "November_B04        : 0.0310\n",
      "\n",
      "============================================================\n",
      "CREATING PREDICTION MAP\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=10)]: Using backend ThreadingBackend with 10 concurrent workers.\n",
      "[Parallel(n_jobs=10)]: Done  30 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=10)]: Done 180 tasks      | elapsed:  8.6min\n",
      "[Parallel(n_jobs=10)]: Done 200 out of 200 | elapsed:  9.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Prediction map created\n",
      "\n",
      "============================================================\n",
      "SAVING RESULTS\n",
      "============================================================\n",
      "✓ Saved metadata.json\n",
      "✓ Saved classification_report.csv\n",
      "✓ Saved feature_importance.csv\n",
      "✓ Saved confusion_matrix.csv\n",
      "✓ Saved prediction_map.tif\n",
      "✓ Saved ground_truth.tif\n",
      "\n",
      "============================================================\n",
      "CREATING VISUALIZATIONS\n",
      "============================================================\n",
      "✓ Saved confusion_matrix.png\n",
      "✓ Saved feature_importance.png\n",
      "✓ Saved prediction_comparison.png\n",
      "✓ Saved error_analysis.png\n",
      "✓ Saved metrics_summary.png\n",
      "\n",
      "\n",
      "RANDOM FOREST CLASSIFICATION RESULTS\n",
      "============================================================\n",
      "\n",
      "City: London\n",
      "Date: 20260111_000353\n",
      "\n",
      "DATA SUMMARY:\n",
      "- Image size: 10980 × 10980 pixels\n",
      "- Total bands: 12\n",
      "- Sample percentage: 1.0%\n",
      "- Training samples: 964,483\n",
      "- Test samples: 24,112,080\n",
      "- Green pixels (test): 12,706 (0.05%)\n",
      "\n",
      "MODEL PERFORMANCE:\n",
      "- Balanced Accuracy: 0.517\n",
      "- F1 Score (Green): 0.055\n",
      "- F1 Score (Macro): 0.528\n",
      "- Precision (Green): 0.150\n",
      "- Recall/Sensitivity (Green): 0.034\n",
      "- Specificity (Non-green): 1.000\n",
      "\n",
      "CONFUSION MATRIX:\n",
      "                Predicted\n",
      "             Non-green    Green\n",
      "Actual Non-g  24,096,923    2,451\n",
      "       Green    12,274      432\n",
      "\n",
      "TOP 5 MOST IMPORTANT BANDS:\n",
      "  April_B04           : 0.1893\n",
      "  April_B08           : 0.1493\n",
      "  April_B03           : 0.1339\n",
      "  April_B02           : 0.1013\n",
      "  August_B04          : 0.0912\n",
      "\n",
      "FILES SAVED:\n",
      "- metadata.json\n",
      "- classification_report.csv\n",
      "- feature_importance.csv\n",
      "- confusion_matrix.csv\n",
      "- prediction_map.tif\n",
      "- ground_truth.tif\n",
      "- confusion_matrix.png\n",
      "- feature_importance.png\n",
      "- prediction_comparison.png\n",
      "- error_analysis.png\n",
      "- metrics_summary.png\n",
      "\n",
      "Results saved to: results/London_20260111_000353\n",
      "\n",
      "============================================================\n",
      "✓ ALL RESULTS SAVED SUCCESSFULLY!\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "import rasterio\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import resample\n",
    "from sklearn.metrics import classification_report, confusion_matrix, balanced_accuracy_score, f1_score\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "SENTINEL_BASE = \"processed_stacks\"\n",
    "CITY = \"London\"\n",
    "OUTPUT_BASE = \"results\"\n",
    "SAMPLE_PERCENTAGE = 0.01\n",
    "os.makedirs(OUTPUT_BASE, exist_ok=True)\n",
    "\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "run_folder = os.path.join(OUTPUT_BASE, f\"{CITY}_{timestamp}\")\n",
    "os.makedirs(run_folder, exist_ok=True)\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(f\"RANDOM FOREST TRAINING - {CITY}\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nResults will be saved to: {run_folder}\\n\")\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"LOADING DATA\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "stack_path = os.path.join(SENTINEL_BASE, f\"{CITY}_MultiMonth_stack.tif\")\n",
    "labels_path = f\"sentinel_data/{CITY}/{CITY}_OSM_labels.tif\"\n",
    "\n",
    "with rasterio.open(stack_path) as src:\n",
    "    X = src.read()\n",
    "    profile = src.profile.copy()\n",
    "    transform = src.transform\n",
    "\n",
    "print(f\"✓ Loaded Sentinel-2 stack: {X.shape}\")\n",
    "\n",
    "with rasterio.open(labels_path) as src:\n",
    "    y = src.read(1)\n",
    "\n",
    "print(f\"✓ Loaded labels: {y.shape}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"PREPARING DATA\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "n_bands, h, w = X.shape\n",
    "X_flat = X.reshape(n_bands, -1).T\n",
    "y_flat = y.flatten()\n",
    "\n",
    "print(f\"Original shape: {h} × {w} = {h*w:,} pixels\")\n",
    "\n",
    "mask = ~np.isnan(X_flat).any(axis=1)\n",
    "X_flat = X_flat[mask]\n",
    "y_flat = y_flat[mask]\n",
    "\n",
    "print(f\"After removing NaN: {len(y_flat):,} pixels\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"CLASS DISTRIBUTION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "unique, counts = np.unique(y_flat, return_counts=True)\n",
    "total = len(y_flat)\n",
    "\n",
    "class_distribution = {}\n",
    "for label, count in zip(unique, counts):\n",
    "    percentage = 100*count/total\n",
    "    class_distribution[f\"Class_{int(label)}\"] = {\n",
    "        \"count\": int(count),\n",
    "        \"percentage\": round(percentage, 2)\n",
    "    }\n",
    "    print(f\"Class {int(label)}: {count:,} samples ({percentage:.2f}%)\")\n",
    "\n",
    "if len(counts) == 2:\n",
    "    imbalance_ratio = counts[0]/counts[1]\n",
    "    print(f\"\\nImbalance ratio: {imbalance_ratio:.1f}:1 (non-green:green)\")\n",
    "    class_distribution[\"imbalance_ratio\"] = round(imbalance_ratio, 2)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"TRAIN-TEST SPLIT\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_flat, y_flat, \n",
    "    test_size=0.2, \n",
    "    random_state=42,\n",
    "    stratify=y_flat\n",
    ")\n",
    "\n",
    "\n",
    "print(f\"Initial train set: {len(y_train):,} samples\")\n",
    "print(f\"Initial test set: {len(y_test):,} samples\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(f\"SAMPLING {SAMPLE_PERCENTAGE*100}% OF TRAINING DATA\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "if SAMPLE_PERCENTAGE < 1.0:\n",
    "    n_samples = int(len(X_train) * SAMPLE_PERCENTAGE)\n",
    "    X_train, y_train = resample(X_train, y_train, \n",
    "                                n_samples=n_samples, \n",
    "                                random_state=42,\n",
    "                                stratify=y_train)\n",
    "    print(f\"✓ Sampled {SAMPLE_PERCENTAGE*100}% of training data: {n_samples:,} pixels\")\n",
    "    print(f\"  Maintains class balance through stratified sampling\")\n",
    "else:\n",
    "    print(f\"Using 100% of training data (no sampling)\")\n",
    "\n",
    "\n",
    "split_info = {\n",
    "    \"train_samples\": int(len(y_train)),\n",
    "    \"test_samples\": int(len(y_test)),\n",
    "    \"sample_percentage\": SAMPLE_PERCENTAGE * 100,\n",
    "    \"train_green\": int(np.sum(y_train==1)),\n",
    "    \"train_green_pct\": round(100*np.mean(y_train==1), 2),\n",
    "    \"test_green\": int(np.sum(y_test==1)),\n",
    "    \"test_green_pct\": round(100*np.mean(y_test==1), 2)\n",
    "}\n",
    "\n",
    "print(f\"Train set: {split_info['train_samples']:,} samples\")\n",
    "print(f\"  Green: {split_info['train_green']:,} ({split_info['train_green_pct']:.2f}%)\")\n",
    "print(f\"Test set: {split_info['test_samples']:,} samples\")\n",
    "print(f\"  Green: {split_info['test_green']:,} ({split_info['test_green_pct']:.2f}%)\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"TRAINING RANDOM FOREST\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "clf = RandomForestClassifier(\n",
    "    n_estimators=200,\n",
    "    max_depth=25,\n",
    "    min_samples_split=10,\n",
    "    min_samples_leaf=5,\n",
    "    class_weight=\"balanced\",\n",
    "    n_jobs=-1,\n",
    "    random_state=42,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "print(\"\\n✓ Training complete!\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"EVALUATION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "report_dict = classification_report(y_test, y_pred, target_names=[\"Non-green\", \"Green\"], output_dict=True)\n",
    "print(classification_report(y_test, y_pred, target_names=[\"Non-green\", \"Green\"]))\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(\"                Predicted\")\n",
    "print(\"              Non-green  Green\")\n",
    "print(f\"Actual Non-g  {cm[0,0]:8d}  {cm[0,1]:6d}\")\n",
    "print(f\"       Green  {cm[1,0]:8d}  {cm[1,1]:6d}\")\n",
    "\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "metrics = {\n",
    "    \"balanced_accuracy\": round(balanced_accuracy_score(y_test, y_pred), 3),\n",
    "    \"f1_green\": round(f1_score(y_test, y_pred, pos_label=1), 3),\n",
    "    \"f1_macro\": round(f1_score(y_test, y_pred, average='macro'), 3),\n",
    "    \"sensitivity\": round(tp / (tp + fn), 3),\n",
    "    \"specificity\": round(tn / (tn + fp), 3),\n",
    "    \"precision_green\": round(report_dict['Green']['precision'], 3),\n",
    "    \"recall_green\": round(report_dict['Green']['recall'], 3)\n",
    "}\n",
    "\n",
    "print(\"\\n\" + \"-\"*60)\n",
    "print(\"SUMMARY METRICS:\")\n",
    "print(\"-\"*60)\n",
    "for key, value in metrics.items():\n",
    "    print(f\"{key:20s}: {value:.3f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"BAND IMPORTANCE\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "months = ['April', 'August', 'November']\n",
    "bands = ['B02', 'B03', 'B04', 'B08']\n",
    "band_names = [f\"{month}_{band}\" for month in months for band in bands]\n",
    "\n",
    "feature_importance = pd.DataFrame({\n",
    "    'band': band_names,\n",
    "    'importance': clf.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(\"\\nTop 10 Most Important Bands:\")\n",
    "for idx, row in feature_importance.head(10).iterrows():\n",
    "    print(f\"{row['band']:20s}: {row['importance']:.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"CREATING PREDICTION MAP\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "X_full_flat = X.reshape(n_bands, -1).T\n",
    "mask_full = ~np.isnan(X_full_flat).any(axis=1)\n",
    "\n",
    "y_pred_full = np.zeros(X_full_flat.shape[0])\n",
    "y_pred_full[mask_full] = clf.predict(X_full_flat[mask_full])\n",
    "y_pred_map = y_pred_full.reshape(h, w)\n",
    "\n",
    "print(\"✓ Prediction map created\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"SAVING RESULTS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "metadata = {\n",
    "    \"city\": CITY,\n",
    "    \"timestamp\": timestamp,\n",
    "    \"image_shape\": {\"height\": h, \"width\": w, \"bands\": n_bands},\n",
    "    \"class_distribution\": class_distribution,\n",
    "    \"split_info\": split_info,\n",
    "    \"metrics\": metrics,\n",
    "    \"model_params\": {\n",
    "        \"n_estimators\": 200,\n",
    "        \"max_depth\": 25,\n",
    "        \"min_samples_split\": 10,\n",
    "        \"min_samples_leaf\": 5,\n",
    "        \"class_weight\": \"balanced\"\n",
    "    }\n",
    "}\n",
    "\n",
    "with open(os.path.join(run_folder, \"metadata.json\"), \"w\") as f:\n",
    "    json.dump(metadata, f, indent=2)\n",
    "print(\"✓ Saved metadata.json\")\n",
    "\n",
    "report_df = pd.DataFrame(report_dict).transpose()\n",
    "report_df.to_csv(os.path.join(run_folder, \"classification_report.csv\"))\n",
    "print(\"✓ Saved classification_report.csv\")\n",
    "\n",
    "feature_importance.to_csv(os.path.join(run_folder, \"feature_importance.csv\"), index=False)\n",
    "print(\"✓ Saved feature_importance.csv\")\n",
    "\n",
    "cm_df = pd.DataFrame(cm, \n",
    "                     index=['Actual_Non-green', 'Actual_Green'],\n",
    "                     columns=['Predicted_Non-green', 'Predicted_Green'])\n",
    "cm_df.to_csv(os.path.join(run_folder, \"confusion_matrix.csv\"))\n",
    "print(\"✓ Saved confusion_matrix.csv\")\n",
    "\n",
    "pred_profile = profile.copy()\n",
    "pred_profile.update(dtype='uint8', count=1, compress='lzw')\n",
    "\n",
    "with rasterio.open(os.path.join(run_folder, \"prediction_map.tif\"), 'w', **pred_profile) as dst:\n",
    "    dst.write(y_pred_map.astype(np.uint8), 1)\n",
    "print(\"✓ Saved prediction_map.tif\")\n",
    "\n",
    "with rasterio.open(os.path.join(run_folder, \"ground_truth.tif\"), 'w', **pred_profile) as dst:\n",
    "    dst.write(y.astype(np.uint8), 1)\n",
    "print(\"✓ Saved ground_truth.tif\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"CREATING VISUALIZATIONS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "im = ax.imshow(cm, cmap='Blues', aspect='auto')\n",
    "ax.set_xticks([0, 1])\n",
    "ax.set_yticks([0, 1])\n",
    "ax.set_xticklabels(['Non-green', 'Green'])\n",
    "ax.set_yticklabels(['Non-green', 'Green'])\n",
    "ax.set_xlabel('Predicted')\n",
    "ax.set_ylabel('Actual')\n",
    "ax.set_title(f'Confusion Matrix - {CITY}')\n",
    "\n",
    "for i in range(2):\n",
    "    for j in range(2):\n",
    "        text = ax.text(j, i, f\"{cm[i, j]:,}\", ha=\"center\", va=\"center\", color=\"black\", fontsize=14)\n",
    "\n",
    "plt.colorbar(im, ax=ax)\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(run_folder, \"confusion_matrix.png\"), dpi=300, bbox_inches='tight')\n",
    "plt.close()\n",
    "print(\"✓ Saved confusion_matrix.png\")\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "top_features = feature_importance.head(12)\n",
    "ax.barh(range(len(top_features)), top_features['importance'])\n",
    "ax.set_yticks(range(len(top_features)))\n",
    "ax.set_yticklabels(top_features['band'])\n",
    "ax.set_xlabel('Importance')\n",
    "ax.set_title(f'Top 12 Band Importance - {CITY}')\n",
    "ax.invert_yaxis()\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(run_folder, \"feature_importance.png\"), dpi=300, bbox_inches='tight')\n",
    "plt.close()\n",
    "print(\"✓ Saved feature_importance.png\")\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "\n",
    "rgb = X[[6, 5, 4], :, :].transpose(1, 2, 0)\n",
    "rgb_norm = np.clip(rgb / 3000, 0, 1)\n",
    "\n",
    "axes[0].imshow(rgb_norm)\n",
    "axes[0].set_title(\"True Color RGB (August)\", fontsize=14)\n",
    "axes[0].axis('off')\n",
    "\n",
    "axes[1].imshow(y, cmap='RdYlGn', vmin=0, vmax=1)\n",
    "axes[1].set_title(\"Ground Truth (OSM)\", fontsize=14)\n",
    "axes[1].axis('off')\n",
    "\n",
    "axes[2].imshow(y_pred_map, cmap='RdYlGn', vmin=0, vmax=1)\n",
    "axes[2].set_title(\"Model Prediction\", fontsize=14)\n",
    "axes[2].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(run_folder, \"prediction_comparison.png\"), dpi=300, bbox_inches='tight')\n",
    "plt.close()\n",
    "print(\"✓ Saved prediction_comparison.png\")\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "\n",
    "false_positives = (y == 0) & (y_pred_map == 1)\n",
    "false_negatives = (y == 1) & (y_pred_map == 0)\n",
    "\n",
    "axes[0].imshow(rgb_norm)\n",
    "axes[0].set_title(\"RGB Image\", fontsize=14)\n",
    "axes[0].axis('off')\n",
    "\n",
    "axes[1].imshow(false_positives, cmap='Reds', vmin=0, vmax=1)\n",
    "axes[1].set_title(f\"False Positives ({np.sum(false_positives):,} pixels)\", fontsize=14)\n",
    "axes[1].axis('off')\n",
    "\n",
    "axes[2].imshow(false_negatives, cmap='Blues', vmin=0, vmax=1)\n",
    "axes[2].set_title(f\"False Negatives ({np.sum(false_negatives):,} pixels)\", fontsize=14)\n",
    "axes[2].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(run_folder, \"error_analysis.png\"), dpi=300, bbox_inches='tight')\n",
    "plt.close()\n",
    "print(\"✓ Saved error_analysis.png\")\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "metric_names = list(metrics.keys())\n",
    "metric_values = list(metrics.values())\n",
    "\n",
    "bars = ax.bar(range(len(metric_names)), metric_values, color='steelblue')\n",
    "ax.set_xticks(range(len(metric_names)))\n",
    "ax.set_xticklabels(metric_names, rotation=45, ha='right')\n",
    "ax.set_ylabel('Score')\n",
    "ax.set_title(f'Model Performance Metrics - {CITY}')\n",
    "ax.set_ylim([0, 1])\n",
    "ax.axhline(y=0.8, color='r', linestyle='--', alpha=0.3, label='0.8 threshold')\n",
    "ax.grid(axis='y', alpha=0.3)\n",
    "ax.legend()\n",
    "\n",
    "for i, (bar, value) in enumerate(zip(bars, metric_values)):\n",
    "    ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.02, \n",
    "            f'{value:.3f}', ha='center', va='bottom', fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(run_folder, \"metrics_summary.png\"), dpi=300, bbox_inches='tight')\n",
    "plt.close()\n",
    "print(\"✓ Saved metrics_summary.png\")\n",
    "\n",
    "summary_text = f\"\"\"\n",
    "RANDOM FOREST CLASSIFICATION RESULTS\n",
    "{'='*60}\n",
    "\n",
    "City: {CITY}\n",
    "Date: {timestamp}\n",
    "\n",
    "DATA SUMMARY:\n",
    "- Image size: {h} × {w} pixels\n",
    "- Total bands: {n_bands}\n",
    "- Sample percentage: {SAMPLE_PERCENTAGE*100}%\n",
    "- Training samples: {split_info['train_samples']:,}\n",
    "- Test samples: {split_info['test_samples']:,}\n",
    "- Green pixels (test): {split_info['test_green']:,} ({split_info['test_green_pct']:.2f}%)\n",
    "\n",
    "MODEL PERFORMANCE:\n",
    "- Balanced Accuracy: {metrics['balanced_accuracy']:.3f}\n",
    "- F1 Score (Green): {metrics['f1_green']:.3f}\n",
    "- F1 Score (Macro): {metrics['f1_macro']:.3f}\n",
    "- Precision (Green): {metrics['precision_green']:.3f}\n",
    "- Recall/Sensitivity (Green): {metrics['recall_green']:.3f}\n",
    "- Specificity (Non-green): {metrics['specificity']:.3f}\n",
    "\n",
    "CONFUSION MATRIX:\n",
    "                Predicted\n",
    "             Non-green    Green\n",
    "Actual Non-g  {cm[0,0]:8,}  {cm[0,1]:7,}\n",
    "       Green  {cm[1,0]:8,}  {cm[1,1]:7,}\n",
    "\n",
    "TOP 5 MOST IMPORTANT BANDS:\n",
    "\"\"\"\n",
    "\n",
    "for idx, row in feature_importance.head(5).iterrows():\n",
    "    summary_text += f\"  {row['band']:20s}: {row['importance']:.4f}\\n\"\n",
    "\n",
    "summary_text += f\"\"\"\n",
    "FILES SAVED:\n",
    "- metadata.json\n",
    "- classification_report.csv\n",
    "- feature_importance.csv\n",
    "- confusion_matrix.csv\n",
    "- prediction_map.tif\n",
    "- ground_truth.tif\n",
    "- confusion_matrix.png\n",
    "- feature_importance.png\n",
    "- prediction_comparison.png\n",
    "- error_analysis.png\n",
    "- metrics_summary.png\n",
    "\n",
    "Results saved to: {run_folder}\n",
    "\"\"\"\n",
    "\n",
    "with open(os.path.join(run_folder, \"SUMMARY.txt\"), \"w\") as f:\n",
    "    f.write(summary_text)\n",
    "\n",
    "print(\"\\n\" + summary_text)\n",
    "print(\"=\"*60)\n",
    "print(\"✓ ALL RESULTS SAVED SUCCESSFULLY!\")\n",
    "print(\"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Infrared City",
   "language": "python",
   "name": "infrared-city"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
