{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sydney Green Space Detection\n",
    "## Training Random Forest with OSM as Ground Truth\n",
    "\n",
    "**Key Features:**\n",
    "- Uses **OpenStreetMap (OSM)** as ground truth for training\n",
    "- Green areas: parks, gardens, forests, grassland, meadows\n",
    "- Multi-temporal Sentinel-2 data (April, August, November)\n",
    "- 21 bands: 4 spectral bands × 3 months + 3 vegetation indices × 3 months"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import rasterio\n",
    "from rasterio.features import rasterize\n",
    "from pathlib import Path\n",
    "import geopandas as gpd\n",
    "import rioxarray as rxr\n",
    "import xarray as xr\n",
    "import osmnx as ox\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"✓ Libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Configuration - Sydney Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base paths\n",
    "BASE_PATH = \"/Users/timgotschim/Documents/LLM/infrared.city\"\n",
    "CITY = \"Sydney\"\n",
    "\n",
    "# Input paths\n",
    "aoi_file = os.path.join(BASE_PATH, \"aois_json/Sydney.geojson\")\n",
    "output_folder = os.path.join(BASE_PATH, \"sentinel_data/Sydney\")\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Sentinel-2 data folders\n",
    "sentinel_folders = {\n",
    "    \"April\": \"/Users/timgotschim/Documents/LLM/AOI_10m/Sydney_APR_R10m\",\n",
    "    \"August\": \"/Users/timgotschim/Documents/LLM/AOI_10m/Sydney_AUG_10m\",\n",
    "    \"November\": \"/Users/timgotschim/Documents/LLM/AOI_10m/Sydney_NOV_10m\"\n",
    "}\n",
    "\n",
    "# Bands to process\n",
    "band_substrings = [\"B02\", \"B03\", \"B04\", \"B08\"]\n",
    "\n",
    "# Output files\n",
    "stack_file = os.path.join(output_folder, \"Sydney_MultiMonth_stack.tif\")\n",
    "osm_file = os.path.join(output_folder, \"Sydney_OSM_green.geojson\")\n",
    "osm_labels_file = os.path.join(output_folder, \"Sydney_OSM_labels.tif\")\n",
    "\n",
    "# Create results folder\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "run_folder = os.path.join(output_folder, f\"run_OSM_{timestamp}\")\n",
    "os.makedirs(run_folder, exist_ok=True)\n",
    "\n",
    "print(\"✓ Configuration loaded\")\n",
    "print(f\"  City: {CITY}\")\n",
    "print(f\"  Output folder: {output_folder}\")\n",
    "print(f\"  Results folder: {run_folder}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Create Multi-Month Stack (21 Bands)\n",
    "### Load and clip Sentinel-2 bands, calculate vegetation indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(f\"PROCESSING {CITY} - Creating 21-band stack\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Load AOI\n",
    "aoi = gpd.read_file(aoi_file)\n",
    "if len(aoi) > 1:\n",
    "    merged_geom = aoi.unary_union\n",
    "    geometries = [merged_geom]\n",
    "else:\n",
    "    geometries = [aoi.geometry.iloc[0]]\n",
    "\n",
    "# Ensure WGS84\n",
    "if aoi.crs is None:\n",
    "    aoi.set_crs(\"EPSG:4326\", inplace=True)\n",
    "if aoi.crs.to_epsg() != 4326:\n",
    "    geometries = [g.to_crs(\"EPSG:4326\") for g in geometries]\n",
    "\n",
    "print(f\"Loaded AOI for {CITY}\")\n",
    "print(f\"AOI bounds: {aoi.total_bounds}\")\n",
    "\n",
    "all_band_arrays = []\n",
    "all_band_names = []\n",
    "\n",
    "# Process each month\n",
    "for month, folder_path in sentinel_folders.items():\n",
    "    print(f\"\\n=== Processing {month} ===\")\n",
    "    \n",
    "    if not os.path.exists(folder_path):\n",
    "        print(f\"WARNING: Folder not found: {folder_path}\")\n",
    "        continue\n",
    "    \n",
    "    month_band_dict = {}\n",
    "    \n",
    "    # Load each band\n",
    "    for substring in band_substrings:\n",
    "        matched_files = glob.glob(os.path.join(folder_path, f\"*{substring}*10m.jp2\"))\n",
    "        if not matched_files:\n",
    "            print(f\"WARNING: No file found for band '{substring}' in {folder_path}\")\n",
    "            continue\n",
    "        \n",
    "        band_path = matched_files[0]\n",
    "        print(f\"Loading: {os.path.basename(band_path)}\")\n",
    "        \n",
    "        band = rxr.open_rasterio(band_path, masked=True).squeeze()\n",
    "        band_clipped = band.rio.clip(geometries, crs=\"EPSG:4326\")\n",
    "        \n",
    "        band_name = f\"{substring}-{month}\"\n",
    "        all_band_arrays.append(band_clipped)\n",
    "        all_band_names.append(band_name)\n",
    "        month_band_dict[substring] = band_clipped\n",
    "        \n",
    "        print(f\"  Clipped {band_name} -> shape: {band_clipped.shape}\")\n",
    "    \n",
    "    # Calculate vegetation indices\n",
    "    if len(month_band_dict) >= 3:\n",
    "        # NDVI\n",
    "        if \"B08\" in month_band_dict and \"B04\" in month_band_dict:\n",
    "            nir = month_band_dict[\"B08\"].astype(np.float32)\n",
    "            red = month_band_dict[\"B04\"].astype(np.float32)\n",
    "            \n",
    "            ndvi = (nir - red) / (nir + red)\n",
    "            ndvi = xr.where(np.isfinite(ndvi), ndvi, np.nan)\n",
    "            ndvi_name = f\"NDVI-{month}\"\n",
    "            all_band_arrays.append(ndvi)\n",
    "            all_band_names.append(ndvi_name)\n",
    "            print(f\"  Calculated {ndvi_name} -> range: [{float(ndvi.min()):.3f}, {float(ndvi.max()):.3f}]\")\n",
    "        \n",
    "        # EVI\n",
    "        if \"B08\" in month_band_dict and \"B04\" in month_band_dict and \"B02\" in month_band_dict:\n",
    "            blue = month_band_dict[\"B02\"].astype(np.float32)\n",
    "            \n",
    "            evi = 2.5 * (nir - red) / (nir + 6*red - 7.5*blue + 1)\n",
    "            evi = xr.where(np.isfinite(evi), evi, np.nan)\n",
    "            evi_name = f\"EVI-{month}\"\n",
    "            all_band_arrays.append(evi)\n",
    "            all_band_names.append(evi_name)\n",
    "            print(f\"  Calculated {evi_name} -> range: [{float(evi.min()):.3f}, {float(evi.max()):.3f}]\")\n",
    "        \n",
    "        # SAVI\n",
    "        if \"B08\" in month_band_dict and \"B04\" in month_band_dict:\n",
    "            L = 0.5\n",
    "            savi = ((nir - red) * (1 + L)) / (nir + red + L)\n",
    "            savi = xr.where(np.isfinite(savi), savi, np.nan)\n",
    "            savi_name = f\"SAVI-{month}\"\n",
    "            all_band_arrays.append(savi)\n",
    "            all_band_names.append(savi_name)\n",
    "            print(f\"  Calculated {savi_name} -> range: [{float(savi.min()):.3f}, {float(savi.max()):.3f}]\")\n",
    "\n",
    "# Stack all bands\n",
    "print(f\"\\n=== Creating final stack ===\")\n",
    "stack = xr.concat(all_band_arrays, dim=\"band\")\n",
    "stack = stack.assign_coords(band=all_band_names)\n",
    "stack = stack.astype(np.float32)\n",
    "\n",
    "print(f\"Stacked all bands -> shape: {stack.shape}\")\n",
    "print(f\"Total bands: {len(all_band_names)}\")\n",
    "print(f\"Band order: {all_band_names}\")\n",
    "\n",
    "# Save as GeoTIFF\n",
    "stack.rio.to_raster(stack_file, dtype=np.float32)\n",
    "print(f\"\\n✓ Saved: {stack_file}\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Fetch OSM Green Space Data\n",
    "### Download ground truth labels from OpenStreetMap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"DOWNLOADING OSM GREEN AREAS FOR SYDNEY\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Define tags for green areas\n",
    "tags = {\n",
    "    \"leisure\": [\"park\", \"garden\"],\n",
    "    \"landuse\": [\"forest\", \"grass\", \"meadow\", \"village_green\"],\n",
    "    \"natural\": [\"wood\", \"scrub\"]\n",
    "}\n",
    "\n",
    "# Load AOI\n",
    "aoi = gpd.read_file(aoi_file)\n",
    "aoi = aoi.to_crs(\"EPSG:4326\")\n",
    "polygon = aoi.geometry.iloc[0]\n",
    "\n",
    "print(\"Fetching green features from OpenStreetMap...\")\n",
    "green_features = ox.features_from_polygon(polygon, tags)\n",
    "\n",
    "# Keep only polygons\n",
    "green_features = green_features[green_features.geometry.type.isin([\"Polygon\", \"MultiPolygon\"])]\n",
    "\n",
    "if len(green_features) == 0:\n",
    "    raise ValueError(\"No green area polygons found in OSM!\")\n",
    "\n",
    "# Calculate total area\n",
    "total_area_km2 = green_features.to_crs('EPSG:3857').area.sum() / 1e6\n",
    "\n",
    "# Save to GeoJSON\n",
    "green_features.to_file(osm_file, driver=\"GeoJSON\")\n",
    "\n",
    "print(f\"✓ Saved: {osm_file}\")\n",
    "print(f\"  Features: {len(green_features)}\")\n",
    "print(f\"  Total area: {total_area_km2:.2f} km²\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Rasterize OSM Labels\n",
    "### Convert vector polygons to raster labels matching Sentinel-2 resolution\n",
    "### Exclude water bodies from green space labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"CREATING RASTERIZED LABELS (WATER EXCLUDED)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Load Sentinel-2 stack metadata\n",
    "with rasterio.open(stack_file) as src:\n",
    "    transform = src.transform\n",
    "    out_shape = (src.height, src.width)\n",
    "    crs = src.crs\n",
    "\n",
    "print(f\"Stack dimensions: {out_shape[0]}x{out_shape[1]} pixels\")\n",
    "\n",
    "# Fetch water bodies to exclude from green labels\n",
    "water_tags = {\n",
    "    \"natural\": [\"water\"],\n",
    "    \"waterway\": [\"river\", \"stream\", \"canal\", \"riverbank\"]\n",
    "}\n",
    "\n",
    "print(\"\\nFetching water features to exclude...\")\n",
    "try:\n",
    "    water_features = ox.features_from_polygon(polygon, water_tags)\n",
    "    water_features = water_features[water_features.geometry.type.isin([\"Polygon\", \"MultiPolygon\"])]\n",
    "    water_features = water_features.to_crs(crs)\n",
    "    print(f\"Found {len(water_features)} water features to exclude\")\n",
    "except Exception as e:\n",
    "    print(f\"No water features found: {e}\")\n",
    "    water_features = gpd.GeoDataFrame()\n",
    "\n",
    "# Load green features and convert to same CRS\n",
    "green_features = gpd.read_file(osm_file)\n",
    "green_features = green_features.to_crs(crs)\n",
    "green_features = green_features[green_features.geometry.type.isin([\"Polygon\", \"MultiPolygon\"])]\n",
    "\n",
    "print(f\"Loaded {len(green_features)} green area polygons\")\n",
    "\n",
    "# Rasterize green areas\n",
    "print(\"\\nRasterizing green areas...\")\n",
    "green_shapes = [(geom, 1) for geom in green_features.geometry]\n",
    "labels = rasterize(\n",
    "    green_shapes,\n",
    "    out_shape=out_shape,\n",
    "    transform=transform,\n",
    "    fill=0,\n",
    "    dtype=np.uint8\n",
    ")\n",
    "\n",
    "# Rasterize water areas and exclude from green labels\n",
    "if len(water_features) > 0:\n",
    "    print(\"Rasterizing water areas to exclude...\")\n",
    "    water_shapes = [(geom, 1) for geom in water_features.geometry]\n",
    "    water_mask = rasterize(\n",
    "        water_shapes,\n",
    "        out_shape=out_shape,\n",
    "        transform=transform,\n",
    "        fill=0,\n",
    "        dtype=np.uint8\n",
    "    )\n",
    "    \n",
    "    # Remove water pixels from green labels\n",
    "    water_removed = np.sum((labels == 1) & (water_mask == 1))\n",
    "    labels[water_mask == 1] = 0\n",
    "    print(f\"Removed {water_removed:,} water pixels from green labels\")\n",
    "\n",
    "# Save labels\n",
    "with rasterio.open(\n",
    "    osm_labels_file, 'w',\n",
    "    driver='GTiff',\n",
    "    height=labels.shape[0],\n",
    "    width=labels.shape[1],\n",
    "    count=1,\n",
    "    dtype=labels.dtype,\n",
    "    crs=crs,\n",
    "    transform=transform,\n",
    "    compress='lzw'\n",
    ") as dst:\n",
    "    dst.write(labels, 1)\n",
    "\n",
    "green_pixels = np.sum(labels == 1)\n",
    "total_pixels = labels.size\n",
    "green_percentage = (green_pixels / total_pixels) * 100\n",
    "\n",
    "print(f\"\\n✓ Completed: {green_pixels:,}/{total_pixels:,} pixels labeled as green ({green_percentage:.2f}%)\")\n",
    "print(f\"✓ Saved: {osm_labels_file}\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Prepare Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"PREPARING TRAINING DATA\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Load Sentinel-2 stack\n",
    "with rasterio.open(stack_file) as src:\n",
    "    X_stack = src.read()  # Shape: (21, 512, 512)\n",
    "\n",
    "# Load OSM labels\n",
    "with rasterio.open(osm_labels_file) as src:\n",
    "    y = src.read(1)  # Shape: (512, 512)\n",
    "\n",
    "print(f\"Sentinel-2 stack shape: {X_stack.shape}\")\n",
    "print(f\"OSM labels shape: {y.shape}\")\n",
    "\n",
    "# Reshape for sklearn: (n_samples, n_features)\n",
    "n_bands = X_stack.shape[0]\n",
    "n_pixels = X_stack.shape[1] * X_stack.shape[2]\n",
    "\n",
    "X = X_stack.reshape(n_bands, -1).T  # Shape: (262144, 21)\n",
    "y_flat = y.flatten()  # Shape: (262144,)\n",
    "\n",
    "# Remove NaN values\n",
    "valid_mask = ~np.isnan(X).any(axis=1)\n",
    "X_clean = X[valid_mask]\n",
    "y_clean = y_flat[valid_mask]\n",
    "\n",
    "print(f\"\\nData after cleaning:\")\n",
    "print(f\"  Valid pixels: {len(X_clean):,}\")\n",
    "print(f\"  Green samples: {np.sum(y_clean == 1):,} ({100*np.sum(y_clean == 1)/len(y_clean):.2f}%)\")\n",
    "print(f\"  Non-green samples: {np.sum(y_clean == 0):,} ({100*np.sum(y_clean == 0)/len(y_clean):.2f}%)\")\n",
    "\n",
    "# Train-test split (80-20)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_clean, y_clean, test_size=0.2, random_state=42, stratify=y_clean\n",
    ")\n",
    "\n",
    "print(f\"\\nTrain-test split:\")\n",
    "print(f\"  Training samples: {len(X_train):,}\")\n",
    "print(f\"  Testing samples: {len(X_test):,}\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Train Random Forest Model\n",
    "### Using OSM as ground truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"TRAINING RANDOM FOREST MODEL\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Initialize Random Forest\n",
    "rf = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=20,\n",
    "    min_samples_split=50,\n",
    "    min_samples_leaf=20,\n",
    "    max_features='sqrt',\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"Training Random Forest...\")\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "print(\"\\n✓ Model trained successfully\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Evaluate Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"EVALUATING MODEL PERFORMANCE\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "# Calculate metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, zero_division=0)\n",
    "recall = recall_score(y_test, y_pred, zero_division=0)\n",
    "f1 = f1_score(y_test, y_pred, zero_division=0)\n",
    "\n",
    "print(f\"\\nModel Performance (trained on OSM):\")\n",
    "print(f\"  Accuracy:  {accuracy:.4f}\")\n",
    "print(f\"  Precision: {precision:.4f}\")\n",
    "print(f\"  Recall:    {recall:.4f}\")\n",
    "print(f\"  F1-Score:  {f1:.4f}\")\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(f\"\\nConfusion Matrix:\")\n",
    "print(cm)\n",
    "\n",
    "# Save metrics\n",
    "metrics = {\n",
    "    \"model\": \"RandomForest\",\n",
    "    \"ground_truth\": \"OpenStreetMap\",\n",
    "    \"accuracy\": float(accuracy),\n",
    "    \"precision\": float(precision),\n",
    "    \"recall\": float(recall),\n",
    "    \"f1_score\": float(f1),\n",
    "    \"confusion_matrix\": cm.tolist()\n",
    "}\n",
    "\n",
    "with open(os.path.join(run_folder, \"metrics.json\"), \"w\") as f:\n",
    "    json.dump(metrics, f, indent=2)\n",
    "\n",
    "print(f\"\\n✓ Metrics saved to: {run_folder}/metrics.json\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Visualize Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=['Non-Green', 'Green'],\n",
    "            yticklabels=['Non-Green', 'Green'])\n",
    "plt.title('Confusion Matrix - Random Forest (OSM GT)', fontsize=14, fontweight='bold')\n",
    "plt.ylabel('True Label')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(run_folder, 'confusion_matrix.png'), dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"✓ Confusion matrix saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Create Prediction Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"CREATING PREDICTION MAP\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Predict for entire image\n",
    "y_pred_all = np.full(n_pixels, np.nan)\n",
    "y_pred_all[valid_mask] = rf.predict(X_clean)\n",
    "\n",
    "# Reshape to image dimensions\n",
    "y_pred_map = y_pred_all.reshape(y.shape)\n",
    "\n",
    "# Save prediction map\n",
    "pred_file = os.path.join(run_folder, 'prediction_map.tif')\n",
    "with rasterio.open(\n",
    "    pred_file, 'w',\n",
    "    driver='GTiff',\n",
    "    height=y_pred_map.shape[0],\n",
    "    width=y_pred_map.shape[1],\n",
    "    count=1,\n",
    "    dtype=np.float32,\n",
    "    crs=crs,\n",
    "    transform=transform,\n",
    "    compress='lzw'\n",
    ") as dst:\n",
    "    dst.write(y_pred_map.astype(np.float32), 1)\n",
    "\n",
    "print(f\"✓ Prediction map saved: {pred_file}\")\n",
    "print(f\"  Predicted green: {np.nansum(y_pred_map == 1)} pixels ({100*np.nansum(y_pred_map == 1)/np.sum(~np.isnan(y_pred_map)):.2f}%)\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Feature Importance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get feature importances\n",
    "importances = rf.feature_importances_\n",
    "band_names = [\n",
    "    'B02-Apr', 'B03-Apr', 'B04-Apr', 'B08-Apr', 'NDVI-Apr', 'EVI-Apr', 'SAVI-Apr',\n",
    "    'B02-Aug', 'B03-Aug', 'B04-Aug', 'B08-Aug', 'NDVI-Aug', 'EVI-Aug', 'SAVI-Aug',\n",
    "    'B02-Nov', 'B03-Nov', 'B04-Nov', 'B08-Nov', 'NDVI-Nov', 'EVI-Nov', 'SAVI-Nov'\n",
    "]\n",
    "\n",
    "# Sort by importance\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "# Plot feature importances\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.barh(range(len(importances)), importances[indices])\n",
    "plt.yticks(range(len(importances)), [band_names[i] for i in indices])\n",
    "plt.xlabel('Feature Importance', fontsize=12)\n",
    "plt.title('Random Forest Feature Importance (OSM GT)', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(run_folder, 'feature_importance.png'), dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"✓ Feature importance plot saved\")\n",
    "print(\"\\nTop 5 most important features:\")\n",
    "for i in range(5):\n",
    "    idx = indices[i]\n",
    "    print(f\"  {i+1}. {band_names[idx]}: {importances[idx]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Comparison Visualization\n",
    "### Compare OSM GT, RF Prediction, and RGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comparison visualization\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "\n",
    "# 1. RGB composite (August)\n",
    "rgb_indices = [7, 8, 9]  # B02-Aug, B03-Aug, B04-Aug (indices in 21-band stack)\n",
    "rgb = X_stack[rgb_indices, :, :].transpose(1, 2, 0)\n",
    "rgb_norm = np.clip(rgb / 3000, 0, 1)\n",
    "axes[0].imshow(rgb_norm)\n",
    "axes[0].set_title(\"RGB (August Sentinel-2)\", fontsize=14, fontweight='bold')\n",
    "axes[0].axis('off')\n",
    "\n",
    "# 2. OSM Ground Truth\n",
    "axes[1].imshow(y, cmap='RdYlGn', vmin=0, vmax=1)\n",
    "axes[1].set_title(f\"OSM Ground Truth\\nGreen: {100*y.sum()/y.size:.1f}%\", \n",
    "                  fontsize=14, fontweight='bold')\n",
    "axes[1].axis('off')\n",
    "\n",
    "# 3. Random Forest Prediction\n",
    "axes[2].imshow(y_pred_map, cmap='RdYlGn', vmin=0, vmax=1)\n",
    "axes[2].set_title(f\"Random Forest Prediction\\nGreen: {100*np.nansum(y_pred_map==1)/np.sum(~np.isnan(y_pred_map)):.1f}%\", \n",
    "                  fontsize=14, fontweight='bold')\n",
    "axes[2].axis('off')\n",
    "\n",
    "plt.suptitle(f'{CITY} - Green Space Detection (OSM-trained)', \n",
    "             fontsize=16, fontweight='bold', y=0.98)\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(run_folder, 'comparison.png'), dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"✓ Comparison visualization saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Summary Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(f\"SYDNEY GREEN SPACE DETECTION - SUMMARY REPORT\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\nGround Truth: OpenStreetMap (OSM)\")\n",
    "print(f\"Green Tags: parks, gardens, forests, grassland, meadows, scrubland\")\n",
    "print(f\"Water bodies excluded from labels\")\n",
    "print(f\"\\nModel Performance:\")\n",
    "print(f\"  Accuracy:  {accuracy:.4f}\")\n",
    "print(f\"  Precision: {precision:.4f}\")\n",
    "print(f\"  Recall:    {recall:.4f}\")\n",
    "print(f\"  F1-Score:  {f1:.4f}\")\n",
    "print(f\"\\nGreen Coverage:\")\n",
    "print(f\"  OSM Ground Truth: {100*y.sum()/y.size:.2f}%\")\n",
    "print(f\"  RF Prediction:    {100*np.nansum(y_pred_map==1)/np.sum(~np.isnan(y_pred_map)):.2f}%\")\n",
    "print(f\"\\nOutput Files:\")\n",
    "print(f\"  Results folder: {run_folder}\")\n",
    "print(f\"  - metrics.json\")\n",
    "print(f\"  - confusion_matrix.png\")\n",
    "print(f\"  - prediction_map.tif\")\n",
    "print(f\"  - feature_importance.png\")\n",
    "print(f\"  - comparison.png\")\n",
    "print(\"=\"*70)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
