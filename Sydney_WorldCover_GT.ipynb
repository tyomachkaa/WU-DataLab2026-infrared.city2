{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sydney Green Space Detection\n",
    "## Training Random Forest with WorldCover 2021 as Ground Truth\n",
    "\n",
    "**Key Features:**\n",
    "- Uses **WorldCover 2021** as ground truth for training\n",
    "- Green classes: Tree cover (10), Shrubland (20), Grassland (30), Mangroves (95)\n",
    "- Multi-temporal Sentinel-2 data (April, August, November)\n",
    "- 21 bands: 4 spectral bands × 3 months + 3 vegetation indices × 3 months"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import rasterio\n",
    "from pathlib import Path\n",
    "import geopandas as gpd\n",
    "import rioxarray as rxr\n",
    "import xarray as xr\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"✓ Libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Configuration - Sydney Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base paths\n",
    "BASE_PATH = \"/Users/timgotschim/Documents/LLM/infrared.city\"\n",
    "CITY = \"Sydney\"\n",
    "\n",
    "# Input paths\n",
    "aoi_file = os.path.join(BASE_PATH, \"aois_json/Sydney.geojson\")\n",
    "output_folder = os.path.join(BASE_PATH, \"sentinel_data/Sydney\")\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Sentinel-2 data folders\n",
    "sentinel_folders = {\n",
    "    \"April\": \"/Users/timgotschim/Documents/LLM/AOI_10m/Sydney_APR_R10m\",\n",
    "    \"August\": \"/Users/timgotschim/Documents/LLM/AOI_10m/Sydney_AUG_10m\",\n",
    "    \"November\": \"/Users/timgotschim/Documents/LLM/AOI_10m/Sydney_NOV_10m\"\n",
    "}\n",
    "\n",
    "# WorldCover path - CHANGE THIS TO YOUR WORLDCOVER FILE\n",
    "worldcover_file = os.path.join(BASE_PATH, \"worldcover/Sydney_WorldCover_2021.tif\")\n",
    "\n",
    "# Bands to process\n",
    "band_substrings = [\"B02\", \"B03\", \"B04\", \"B08\"]\n",
    "\n",
    "# Output files\n",
    "stack_file = os.path.join(output_folder, \"Sydney_MultiMonth_stack.tif\")\n",
    "worldcover_labels_file = os.path.join(output_folder, \"Sydney_WorldCover_labels.tif\")\n",
    "\n",
    "# Create results folder\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "run_folder = os.path.join(output_folder, f\"run_{timestamp}\")\n",
    "os.makedirs(run_folder, exist_ok=True)\n",
    "\n",
    "print(\"✓ Configuration loaded\")\n",
    "print(f\"  City: {CITY}\")\n",
    "print(f\"  Output folder: {output_folder}\")\n",
    "print(f\"  Results folder: {run_folder}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Create Multi-Month Stack (21 Bands)\n",
    "### Load and clip Sentinel-2 bands, calculate vegetation indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(f\"PROCESSING {CITY} - Creating 21-band stack\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Load AOI\n",
    "aoi = gpd.read_file(aoi_file)\n",
    "if len(aoi) > 1:\n",
    "    merged_geom = aoi.unary_union\n",
    "    geometries = [merged_geom]\n",
    "else:\n",
    "    geometries = [aoi.geometry.iloc[0]]\n",
    "\n",
    "# Ensure WGS84\n",
    "if aoi.crs is None:\n",
    "    aoi.set_crs(\"EPSG:4326\", inplace=True)\n",
    "if aoi.crs.to_epsg() != 4326:\n",
    "    geometries = [g.to_crs(\"EPSG:4326\") for g in geometries]\n",
    "\n",
    "print(f\"Loaded AOI for {CITY}\")\n",
    "print(f\"AOI bounds: {aoi.total_bounds}\")\n",
    "\n",
    "all_band_arrays = []\n",
    "all_band_names = []\n",
    "\n",
    "# Process each month\n",
    "for month, folder_path in sentinel_folders.items():\n",
    "    print(f\"\\n=== Processing {month} ===\")\n",
    "    \n",
    "    if not os.path.exists(folder_path):\n",
    "        print(f\"WARNING: Folder not found: {folder_path}\")\n",
    "        continue\n",
    "    \n",
    "    month_band_dict = {}\n",
    "    \n",
    "    # Load each band\n",
    "    for substring in band_substrings:\n",
    "        matched_files = glob.glob(os.path.join(folder_path, f\"*{substring}*10m.jp2\"))\n",
    "        if not matched_files:\n",
    "            print(f\"WARNING: No file found for band '{substring}' in {folder_path}\")\n",
    "            continue\n",
    "        \n",
    "        band_path = matched_files[0]\n",
    "        print(f\"Loading: {os.path.basename(band_path)}\")\n",
    "        \n",
    "        band = rxr.open_rasterio(band_path, masked=True).squeeze()\n",
    "        band_clipped = band.rio.clip(geometries, crs=\"EPSG:4326\")\n",
    "        \n",
    "        band_name = f\"{substring}-{month}\"\n",
    "        all_band_arrays.append(band_clipped)\n",
    "        all_band_names.append(band_name)\n",
    "        month_band_dict[substring] = band_clipped\n",
    "        \n",
    "        print(f\"  Clipped {band_name} -> shape: {band_clipped.shape}\")\n",
    "    \n",
    "    # Calculate vegetation indices\n",
    "    if len(month_band_dict) >= 3:\n",
    "        # NDVI\n",
    "        if \"B08\" in month_band_dict and \"B04\" in month_band_dict:\n",
    "            nir = month_band_dict[\"B08\"].astype(np.float32)\n",
    "            red = month_band_dict[\"B04\"].astype(np.float32)\n",
    "            \n",
    "            ndvi = (nir - red) / (nir + red)\n",
    "            ndvi = xr.where(np.isfinite(ndvi), ndvi, np.nan)\n",
    "            ndvi_name = f\"NDVI-{month}\"\n",
    "            all_band_arrays.append(ndvi)\n",
    "            all_band_names.append(ndvi_name)\n",
    "            print(f\"  Calculated {ndvi_name} -> range: [{float(ndvi.min()):.3f}, {float(ndvi.max()):.3f}]\")\n",
    "        \n",
    "        # EVI\n",
    "        if \"B08\" in month_band_dict and \"B04\" in month_band_dict and \"B02\" in month_band_dict:\n",
    "            blue = month_band_dict[\"B02\"].astype(np.float32)\n",
    "            \n",
    "            evi = 2.5 * (nir - red) / (nir + 6*red - 7.5*blue + 1)\n",
    "            evi = xr.where(np.isfinite(evi), evi, np.nan)\n",
    "            evi_name = f\"EVI-{month}\"\n",
    "            all_band_arrays.append(evi)\n",
    "            all_band_names.append(evi_name)\n",
    "            print(f\"  Calculated {evi_name} -> range: [{float(evi.min()):.3f}, {float(evi.max()):.3f}]\")\n",
    "        \n",
    "        # SAVI\n",
    "        if \"B08\" in month_band_dict and \"B04\" in month_band_dict:\n",
    "            L = 0.5\n",
    "            savi = ((nir - red) * (1 + L)) / (nir + red + L)\n",
    "            savi = xr.where(np.isfinite(savi), savi, np.nan)\n",
    "            savi_name = f\"SAVI-{month}\"\n",
    "            all_band_arrays.append(savi)\n",
    "            all_band_names.append(savi_name)\n",
    "            print(f\"  Calculated {savi_name} -> range: [{float(savi.min()):.3f}, {float(savi.max()):.3f}]\")\n",
    "\n",
    "# Stack all bands\n",
    "print(f\"\\n=== Creating final stack ===\")\n",
    "stack = xr.concat(all_band_arrays, dim=\"band\")\n",
    "stack = stack.assign_coords(band=all_band_names)\n",
    "stack = stack.astype(np.float32)\n",
    "\n",
    "print(f\"Stacked all bands -> shape: {stack.shape}\")\n",
    "print(f\"Total bands: {len(all_band_names)}\")\n",
    "print(f\"Band order: {all_band_names}\")\n",
    "\n",
    "# Save as GeoTIFF\n",
    "stack.rio.to_raster(stack_file, dtype=np.float32)\n",
    "print(f\"\\n✓ Saved: {stack_file}\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Load WorldCover as Ground Truth\n",
    "### WorldCover 2021 provides global land cover classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"LOADING WORLDCOVER 2021 AS GROUND TRUTH\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "if not os.path.exists(worldcover_file):\n",
    "    raise FileNotFoundError(f\"WorldCover file not found: {worldcover_file}\")\n",
    "\n",
    "# Load Sentinel-2 stack metadata for alignment\n",
    "with rasterio.open(stack_file) as src:\n",
    "    stack_transform = src.transform\n",
    "    stack_shape = (src.height, src.width)\n",
    "    stack_crs = src.crs\n",
    "    stack_bounds = src.bounds\n",
    "\n",
    "print(f\"Stack dimensions: {stack_shape[0]}x{stack_shape[1]} pixels\")\n",
    "print(f\"Stack CRS: {stack_crs}\")\n",
    "\n",
    "# Load and reproject WorldCover to match Sentinel-2 stack\n",
    "with rasterio.open(worldcover_file) as src:\n",
    "    from rasterio.warp import reproject, Resampling\n",
    "    \n",
    "    worldcover_data = np.empty(stack_shape, dtype=np.uint8)\n",
    "    \n",
    "    reproject(\n",
    "        source=rasterio.band(src, 1),\n",
    "        destination=worldcover_data,\n",
    "        src_transform=src.transform,\n",
    "        src_crs=src.crs,\n",
    "        dst_transform=stack_transform,\n",
    "        dst_crs=stack_crs,\n",
    "        resampling=Resampling.nearest\n",
    "    )\n",
    "\n",
    "# Convert WorldCover classes to binary green/non-green\n",
    "# WorldCover legend:\n",
    "# 10 = Tree cover\n",
    "# 20 = Shrubland  \n",
    "# 30 = Grassland\n",
    "# 40 = Cropland\n",
    "# 50 = Built-up\n",
    "# 60 = Bare / sparse vegetation\n",
    "# 70 = Snow and ice\n",
    "# 80 = Permanent water bodies\n",
    "# 90 = Herbaceous wetland\n",
    "# 95 = Mangroves\n",
    "# 100 = Moss and lichen\n",
    "\n",
    "GREEN_CLASSES = [10, 20, 30, 95]  # Tree, Shrub, Grass, Mangroves\n",
    "labels = np.isin(worldcover_data, GREEN_CLASSES).astype(np.uint8)\n",
    "\n",
    "# Save WorldCover-derived labels\n",
    "with rasterio.open(\n",
    "    worldcover_labels_file, 'w',\n",
    "    driver='GTiff',\n",
    "    height=labels.shape[0],\n",
    "    width=labels.shape[1],\n",
    "    count=1,\n",
    "    dtype=labels.dtype,\n",
    "    crs=stack_crs,\n",
    "    transform=stack_transform,\n",
    "    compress='lzw'\n",
    ") as dst:\n",
    "    dst.write(labels, 1)\n",
    "\n",
    "green_pixels = np.sum(labels == 1)\n",
    "total_pixels = labels.size\n",
    "green_percentage = (green_pixels / total_pixels) * 100\n",
    "\n",
    "print(f\"\\n✓ WorldCover processed successfully\")\n",
    "print(f\"  Green classes: {GREEN_CLASSES}\")\n",
    "print(f\"  Green pixels: {green_pixels:,} ({green_percentage:.2f}%)\")\n",
    "print(f\"  Non-green pixels: {total_pixels - green_pixels:,} ({100-green_percentage:.2f}%)\")\n",
    "print(f\"✓ Saved: {worldcover_labels_file}\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Prepare Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"PREPARING TRAINING DATA\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Load Sentinel-2 stack\n",
    "with rasterio.open(stack_file) as src:\n",
    "    X_stack = src.read()  # Shape: (21, 512, 512)\n",
    "\n",
    "# Load WorldCover labels\n",
    "with rasterio.open(worldcover_labels_file) as src:\n",
    "    y = src.read(1)  # Shape: (512, 512)\n",
    "\n",
    "print(f\"Sentinel-2 stack shape: {X_stack.shape}\")\n",
    "print(f\"WorldCover labels shape: {y.shape}\")\n",
    "\n",
    "# Reshape for sklearn: (n_samples, n_features)\n",
    "n_bands = X_stack.shape[0]\n",
    "n_pixels = X_stack.shape[1] * X_stack.shape[2]\n",
    "\n",
    "X = X_stack.reshape(n_bands, -1).T  # Shape: (262144, 21)\n",
    "y_flat = y.flatten()  # Shape: (262144,)\n",
    "\n",
    "# Remove NaN values\n",
    "valid_mask = ~np.isnan(X).any(axis=1)\n",
    "X_clean = X[valid_mask]\n",
    "y_clean = y_flat[valid_mask]\n",
    "\n",
    "print(f\"\\nData after cleaning:\")\n",
    "print(f\"  Valid pixels: {len(X_clean):,}\")\n",
    "print(f\"  Green samples: {np.sum(y_clean == 1):,} ({100*np.sum(y_clean == 1)/len(y_clean):.2f}%)\")\n",
    "print(f\"  Non-green samples: {np.sum(y_clean == 0):,} ({100*np.sum(y_clean == 0)/len(y_clean):.2f}%)\")\n",
    "\n",
    "# Train-test split (80-20)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_clean, y_clean, test_size=0.2, random_state=42, stratify=y_clean\n",
    ")\n",
    "\n",
    "print(f\"\\nTrain-test split:\")\n",
    "print(f\"  Training samples: {len(X_train):,}\")\n",
    "print(f\"  Testing samples: {len(X_test):,}\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Train Random Forest Model\n",
    "### Using WorldCover as ground truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"TRAINING RANDOM FOREST MODEL\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Initialize Random Forest\n",
    "rf = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=20,\n",
    "    min_samples_split=50,\n",
    "    min_samples_leaf=20,\n",
    "    max_features='sqrt',\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"Training Random Forest...\")\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "print(\"\\n✓ Model trained successfully\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Evaluate Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"EVALUATING MODEL PERFORMANCE\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "# Calculate metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, zero_division=0)\n",
    "recall = recall_score(y_test, y_pred, zero_division=0)\n",
    "f1 = f1_score(y_test, y_pred, zero_division=0)\n",
    "\n",
    "print(f\"\\nModel Performance (trained on WorldCover):\")\n",
    "print(f\"  Accuracy:  {accuracy:.4f}\")\n",
    "print(f\"  Precision: {precision:.4f}\")\n",
    "print(f\"  Recall:    {recall:.4f}\")\n",
    "print(f\"  F1-Score:  {f1:.4f}\")\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(f\"\\nConfusion Matrix:\")\n",
    "print(cm)\n",
    "\n",
    "# Save metrics\n",
    "metrics = {\n",
    "    \"model\": \"RandomForest\",\n",
    "    \"ground_truth\": \"WorldCover_2021\",\n",
    "    \"accuracy\": float(accuracy),\n",
    "    \"precision\": float(precision),\n",
    "    \"recall\": float(recall),\n",
    "    \"f1_score\": float(f1),\n",
    "    \"confusion_matrix\": cm.tolist()\n",
    "}\n",
    "\n",
    "with open(os.path.join(run_folder, \"metrics.json\"), \"w\") as f:\n",
    "    json.dump(metrics, f, indent=2)\n",
    "\n",
    "print(f\"\\n✓ Metrics saved to: {run_folder}/metrics.json\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Visualize Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=['Non-Green', 'Green'],\n",
    "            yticklabels=['Non-Green', 'Green'])\n",
    "plt.title('Confusion Matrix - Random Forest (WorldCover GT)', fontsize=14, fontweight='bold')\n",
    "plt.ylabel('True Label')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(run_folder, 'confusion_matrix.png'), dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"✓ Confusion matrix saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Create Prediction Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"CREATING PREDICTION MAP\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Predict for entire image\n",
    "y_pred_all = np.full(n_pixels, np.nan)\n",
    "y_pred_all[valid_mask] = rf.predict(X_clean)\n",
    "\n",
    "# Reshape to image dimensions\n",
    "y_pred_map = y_pred_all.reshape(y.shape)\n",
    "\n",
    "# Save prediction map\n",
    "pred_file = os.path.join(run_folder, 'prediction_map.tif')\n",
    "with rasterio.open(\n",
    "    pred_file, 'w',\n",
    "    driver='GTiff',\n",
    "    height=y_pred_map.shape[0],\n",
    "    width=y_pred_map.shape[1],\n",
    "    count=1,\n",
    "    dtype=np.float32,\n",
    "    crs=stack_crs,\n",
    "    transform=stack_transform,\n",
    "    compress='lzw'\n",
    ") as dst:\n",
    "    dst.write(y_pred_map.astype(np.float32), 1)\n",
    "\n",
    "print(f\"✓ Prediction map saved: {pred_file}\")\n",
    "print(f\"  Predicted green: {np.nansum(y_pred_map == 1)} pixels ({100*np.nansum(y_pred_map == 1)/np.sum(~np.isnan(y_pred_map)):.2f}%)\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Feature Importance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get feature importances\n",
    "importances = rf.feature_importances_\n",
    "band_names = [\n",
    "    'B02-Apr', 'B03-Apr', 'B04-Apr', 'B08-Apr', 'NDVI-Apr', 'EVI-Apr', 'SAVI-Apr',\n",
    "    'B02-Aug', 'B03-Aug', 'B04-Aug', 'B08-Aug', 'NDVI-Aug', 'EVI-Aug', 'SAVI-Aug',\n",
    "    'B02-Nov', 'B03-Nov', 'B04-Nov', 'B08-Nov', 'NDVI-Nov', 'EVI-Nov', 'SAVI-Nov'\n",
    "]\n",
    "\n",
    "# Sort by importance\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "# Plot feature importances\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.barh(range(len(importances)), importances[indices])\n",
    "plt.yticks(range(len(importances)), [band_names[i] for i in indices])\n",
    "plt.xlabel('Feature Importance', fontsize=12)\n",
    "plt.title('Random Forest Feature Importance (WorldCover GT)', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(run_folder, 'feature_importance.png'), dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"✓ Feature importance plot saved\")\n",
    "print(\"\\nTop 5 most important features:\")\n",
    "for i in range(5):\n",
    "    idx = indices[i]\n",
    "    print(f\"  {i+1}. {band_names[idx]}: {importances[idx]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Comparison Visualization\n",
    "### Compare WorldCover GT, RF Prediction, and RGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comparison visualization\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "\n",
    "# 1. RGB composite (August)\n",
    "rgb_indices = [8, 9, 10]  # B02-Aug, B03-Aug, B04-Aug\n",
    "rgb = X_stack[rgb_indices, :, :].transpose(1, 2, 0)\n",
    "rgb_norm = np.clip(rgb / 3000, 0, 1)\n",
    "axes[0].imshow(rgb_norm)\n",
    "axes[0].set_title(\"RGB (August Sentinel-2)\", fontsize=14, fontweight='bold')\n",
    "axes[0].axis('off')\n",
    "\n",
    "# 2. WorldCover Ground Truth\n",
    "axes[1].imshow(y, cmap='RdYlGn', vmin=0, vmax=1)\n",
    "axes[1].set_title(f\"WorldCover 2021 Ground Truth\\nGreen: {100*y.sum()/y.size:.1f}%\", \n",
    "                  fontsize=14, fontweight='bold')\n",
    "axes[1].axis('off')\n",
    "\n",
    "# 3. Random Forest Prediction\n",
    "axes[2].imshow(y_pred_map, cmap='RdYlGn', vmin=0, vmax=1)\n",
    "axes[2].set_title(f\"Random Forest Prediction\\nGreen: {100*np.nansum(y_pred_map==1)/np.sum(~np.isnan(y_pred_map)):.1f}%\", \n",
    "                  fontsize=14, fontweight='bold')\n",
    "axes[2].axis('off')\n",
    "\n",
    "plt.suptitle(f'{CITY} - Green Space Detection (WorldCover-trained)', \n",
    "             fontsize=16, fontweight='bold', y=0.98)\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(run_folder, 'comparison.png'), dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"✓ Comparison visualization saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Summary Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(f\"SYDNEY GREEN SPACE DETECTION - SUMMARY REPORT\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\nGround Truth: WorldCover 2021\")\n",
    "print(f\"Green Classes: Tree cover (10), Shrubland (20), Grassland (30), Mangroves (95)\")\n",
    "print(f\"\\nModel Performance:\")\n",
    "print(f\"  Accuracy:  {accuracy:.4f}\")\n",
    "print(f\"  Precision: {precision:.4f}\")\n",
    "print(f\"  Recall:    {recall:.4f}\")\n",
    "print(f\"  F1-Score:  {f1:.4f}\")\n",
    "print(f\"\\nGreen Coverage:\")\n",
    "print(f\"  WorldCover GT: {100*y.sum()/y.size:.2f}%\")\n",
    "print(f\"  RF Prediction: {100*np.nansum(y_pred_map==1)/np.sum(~np.isnan(y_pred_map)):.2f}%\")\n",
    "print(f\"\\nOutput Files:\")\n",
    "print(f\"  Results folder: {run_folder}\")\n",
    "print(f\"  - metrics.json\")\n",
    "print(f\"  - confusion_matrix.png\")\n",
    "print(f\"  - prediction_map.tif\")\n",
    "print(f\"  - feature_importance.png\")\n",
    "print(f\"  - comparison.png\")\n",
    "print(\"=\"*70)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
