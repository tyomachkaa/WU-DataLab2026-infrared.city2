{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "350d5d86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved aois_json/Vienna.geojson\n",
      "Saved aois_json/Paris.geojson\n",
      "Saved aois_json/London.geojson\n",
      "Saved aois_json/Toronto.geojson\n",
      "Saved aois_json/Vancouver.geojson\n",
      "Saved aois_json/San_Francisco.geojson\n",
      "Saved aois_json/Lisbon.geojson\n",
      "Saved aois_json/Madrid.geojson\n",
      "Saved aois_json/Barcelona.geojson\n",
      "Saved aois_json/Berlin.geojson\n",
      "Saved aois_json/Amsterdam.geojson\n",
      "Saved aois_json/Melbourne.geojson\n",
      "Saved aois_json/Sydney.geojson\n",
      "Saved aois_json/Auckland.geojson\n",
      "Saved aois_json/Seattle.geojson\n",
      "All 15 city AOIs saved as separate GeoJSON files in 'aois_json' folder.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import shapely.geometry\n",
    "from shapely.ops import transform\n",
    "import pyproj\n",
    "\n",
    "# Make folder if it doesn't exist\n",
    "folder = \"aois_json\"\n",
    "os.makedirs(folder, exist_ok=True)\n",
    "\n",
    "# City centers: (lon, lat)\n",
    "cities = {\n",
    "    \"Vienna\": (16.3738, 48.2082),\n",
    "    \"Paris\": (2.3522, 48.8566),\n",
    "    \"London\": (-0.1276, 51.5074),\n",
    "    \"Toronto\": (-79.3832, 43.6532),\n",
    "    \"Vancouver\": (-123.1207, 49.2827),\n",
    "    \"San Francisco\": (-122.4194, 37.7749),\n",
    "    \"Lisbon\": (-9.1393, 38.7223),\n",
    "    \"Madrid\": (-3.7038, 40.4168),\n",
    "    \"Barcelona\": (2.1734, 41.3851),\n",
    "    \"Berlin\": (13.4050, 52.5200),\n",
    "    \"Amsterdam\": (4.9041, 52.3676),\n",
    "    \"Melbourne\": (144.9631, -37.8136),\n",
    "    \"Sydney\": (151.2093, -33.8688),\n",
    "    \"Auckland\": (174.7633, -36.8485),\n",
    "    \"Seattle\": (-122.3321, 47.6062)\n",
    "}\n",
    "\n",
    "# AOI size in meters (~5.12 km to match 512x512 pixels at 10 m)\n",
    "size_m = 512 * 10  \n",
    "\n",
    "def create_square_aoi(center_lon, center_lat, size_m):\n",
    "    \"\"\"\n",
    "    Create a square AOI of size_m x size_m around the city center.\n",
    "    \"\"\"\n",
    "    utm_zone = int((center_lon + 180) / 6) + 1\n",
    "    utm = pyproj.Proj(proj='utm', zone=utm_zone, ellps='WGS84')\n",
    "    wgs84 = pyproj.Proj(proj='latlong', datum='WGS84')\n",
    "\n",
    "    project_to_utm = pyproj.Transformer.from_proj(wgs84, utm, always_xy=True).transform\n",
    "    project_to_wgs = pyproj.Transformer.from_proj(utm, wgs84, always_xy=True).transform\n",
    "\n",
    "    point = shapely.geometry.Point(center_lon, center_lat)\n",
    "    point_utm = transform(project_to_utm, point)\n",
    "\n",
    "    half_size = size_m / 2\n",
    "    square_utm = shapely.geometry.box(\n",
    "        point_utm.x - half_size,\n",
    "        point_utm.y - half_size,\n",
    "        point_utm.x + half_size,\n",
    "        point_utm.y + half_size\n",
    "    )\n",
    "\n",
    "    square_wgs = transform(project_to_wgs, square_utm)\n",
    "    return square_wgs\n",
    "\n",
    "# Generate one JSON per city\n",
    "for city, (lon, lat) in cities.items():\n",
    "    square = create_square_aoi(lon, lat, size_m)\n",
    "    polygon_coords = [list(coord) for coord in square.exterior.coords]\n",
    "    geojson = {\n",
    "        \"type\": \"FeatureCollection\",\n",
    "        \"features\": [\n",
    "            {\n",
    "                \"type\": \"Feature\",\n",
    "                \"properties\": {\"city\": city},\n",
    "                \"geometry\": {\"type\": \"Polygon\", \"coordinates\": [polygon_coords]}\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "    filepath = os.path.join(folder, f\"{city.replace(' ', '_')}.geojson\")\n",
    "    with open(filepath, \"w\") as f:\n",
    "        json.dump(geojson, f, indent=2)\n",
    "    print(f\"Saved {filepath}\")\n",
    "\n",
    "print(\"All 15 city AOIs saved as separate GeoJSON files in 'aois_json' folder.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a699d1a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "SENTINEL-2 MULTI-MONTH PREPROCESSING PIPELINE\n",
      "============================================================\n",
      "\n",
      "Base path: /Users/timgotschim/Documents/LLM/AOI_10m\n",
      "Cities: Sydney, Toronto, Vancouver, Vienna, Warsaw\n",
      "Months: April, August, November\n",
      "Bands: B02, B03, B04, B08\n",
      "Output folder: processed_stacks\n",
      "\n",
      "============================================================\n",
      "PROCESSING CITY: Sydney\n",
      "============================================================\n",
      "\n",
      "=== Processing Sydney - April ===\n",
      "  Loading bands from: Sydney_APR_R10m\n",
      "      ✓ Found B02: T56HLH_20250419T235311_B02_10m.jp2\n",
      "    ✓ Loading B02: T56HLH_20250419T235311_B02_10m.jp2\n",
      "      ✓ Found B03: T56HLH_20250419T235311_B03_10m.jp2\n",
      "    ✓ Loading B03: T56HLH_20250419T235311_B03_10m.jp2\n",
      "      ✓ Found B04: T56HLH_20250419T235311_B04_10m.jp2\n",
      "    ✓ Loading B04: T56HLH_20250419T235311_B04_10m.jp2\n",
      "      ✓ Found B08: T56HLH_20250419T235311_B08_10m.jp2\n",
      "    ✓ Loading B08: T56HLH_20250419T235311_B08_10m.jp2\n",
      "  ✓ Loaded 4 bands, shape: (4, 10980, 10980)\n",
      "\n",
      "=== Processing Sydney - August ===\n",
      "  Loading bands from: Sydney_AUG_10m\n",
      "      ✓ Found B02: T56HLH_20250831T000301_B02_10m.jp2\n",
      "    ✓ Loading B02: T56HLH_20250831T000301_B02_10m.jp2\n",
      "      ✓ Found B03: T56HLH_20250831T000301_B03_10m.jp2\n",
      "    ✓ Loading B03: T56HLH_20250831T000301_B03_10m.jp2\n",
      "      ✓ Found B04: T56HLH_20250831T000301_B04_10m.jp2\n",
      "    ✓ Loading B04: T56HLH_20250831T000301_B04_10m.jp2\n",
      "      ✓ Found B08: T56HLH_20250831T000301_B08_10m.jp2\n",
      "    ✓ Loading B08: T56HLH_20250831T000301_B08_10m.jp2\n",
      "  ✓ Loaded 4 bands, shape: (4, 10980, 10980)\n",
      "\n",
      "=== Processing Sydney - November ===\n",
      "  Loading bands from: Sydney_NOV_10m\n",
      "      ✓ Found B02: T56HLH_20251119T000311_B02_10m.jp2\n",
      "    ✓ Loading B02: T56HLH_20251119T000311_B02_10m.jp2\n",
      "      ✓ Found B03: T56HLH_20251119T000311_B03_10m.jp2\n",
      "    ✓ Loading B03: T56HLH_20251119T000311_B03_10m.jp2\n",
      "      ✓ Found B04: T56HLH_20251119T000311_B04_10m.jp2\n",
      "    ✓ Loading B04: T56HLH_20251119T000311_B04_10m.jp2\n",
      "      ✓ Found B08: T56HLH_20251119T000311_B08_10m.jp2\n",
      "    ✓ Loading B08: T56HLH_20251119T000311_B08_10m.jp2\n",
      "  ✓ Loaded 4 bands, shape: (4, 10980, 10980)\n",
      "\n",
      "============================================================\n",
      "CREATING MULTI-MONTH STACK\n",
      "============================================================\n",
      "  Final stack shape: (12, 10980, 10980)\n",
      "  Total bands: 12 (3 months × 4 bands)\n",
      "\n",
      "  Saving to: processed_stacks/Sydney_MultiMonth_stack.tif\n",
      "  ✓ Stack saved successfully!\n",
      "\n",
      "  Stack Statistics:\n",
      "    Min: 0.00\n",
      "    Max: 19904.00\n",
      "    Mean: 1190.80\n",
      "    NaN pixels: 0\n",
      "\n",
      "============================================================\n",
      "PROCESSING CITY: Toronto\n",
      "============================================================\n",
      "\n",
      "=== Processing Toronto - April ===\n",
      "  WARNING: Folder not found: /Users/timgotschim/Documents/LLM/AOI_10m/Toronto_APR_R10m\n",
      "  Skipping April for Toronto...\n",
      "\n",
      "=== Processing Toronto - August ===\n",
      "  WARNING: Folder not found: /Users/timgotschim/Documents/LLM/AOI_10m/Toronto_AUG_10m\n",
      "  Skipping August for Toronto...\n",
      "\n",
      "=== Processing Toronto - November ===\n",
      "  WARNING: Folder not found: /Users/timgotschim/Documents/LLM/AOI_10m/Toronto_NOV_10m\n",
      "  Skipping November for Toronto...\n",
      "\n",
      "  ERROR: No data loaded for Toronto, skipping stack creation\n",
      "\n",
      "============================================================\n",
      "PROCESSING CITY: Vancouver\n",
      "============================================================\n",
      "\n",
      "=== Processing Vancouver - April ===\n",
      "  WARNING: Folder not found: /Users/timgotschim/Documents/LLM/AOI_10m/Vancouver_APR_R10m\n",
      "  Skipping April for Vancouver...\n",
      "\n",
      "=== Processing Vancouver - August ===\n",
      "  WARNING: Folder not found: /Users/timgotschim/Documents/LLM/AOI_10m/Vancouver_AUG_10m\n",
      "  Skipping August for Vancouver...\n",
      "\n",
      "=== Processing Vancouver - November ===\n",
      "  WARNING: Folder not found: /Users/timgotschim/Documents/LLM/AOI_10m/Vancouver_NOV_10m\n",
      "  Skipping November for Vancouver...\n",
      "\n",
      "  ERROR: No data loaded for Vancouver, skipping stack creation\n",
      "\n",
      "============================================================\n",
      "PROCESSING CITY: Vienna\n",
      "============================================================\n",
      "\n",
      "=== Processing Vienna - April ===\n",
      "  WARNING: Folder not found: /Users/timgotschim/Documents/LLM/AOI_10m/Vienna_APR_R10m\n",
      "  Skipping April for Vienna...\n",
      "\n",
      "=== Processing Vienna - August ===\n",
      "  WARNING: Folder not found: /Users/timgotschim/Documents/LLM/AOI_10m/Vienna_AUG_10m\n",
      "  Skipping August for Vienna...\n",
      "\n",
      "=== Processing Vienna - November ===\n",
      "  WARNING: Folder not found: /Users/timgotschim/Documents/LLM/AOI_10m/Vienna_NOV_10m\n",
      "  Skipping November for Vienna...\n",
      "\n",
      "  ERROR: No data loaded for Vienna, skipping stack creation\n",
      "\n",
      "============================================================\n",
      "PROCESSING CITY: Warsaw\n",
      "============================================================\n",
      "\n",
      "=== Processing Warsaw - April ===\n",
      "  WARNING: Folder not found: /Users/timgotschim/Documents/LLM/AOI_10m/Warsaw_APR_R10m\n",
      "  Skipping April for Warsaw...\n",
      "\n",
      "=== Processing Warsaw - August ===\n",
      "  WARNING: Folder not found: /Users/timgotschim/Documents/LLM/AOI_10m/Warsaw_AUG_10m\n",
      "  Skipping August for Warsaw...\n",
      "\n",
      "=== Processing Warsaw - November ===\n",
      "  WARNING: Folder not found: /Users/timgotschim/Documents/LLM/AOI_10m/Warsaw_NOV_10m\n",
      "  Skipping November for Warsaw...\n",
      "\n",
      "  ERROR: No data loaded for Warsaw, skipping stack creation\n",
      "\n",
      "\n",
      "============================================================\n",
      "PROCESSING SUMMARY\n",
      "============================================================\n",
      "\n",
      "✓ Successfully processed: 1 cities\n",
      "  - Sydney\n",
      "\n",
      "✗ Failed: 4 cities\n",
      "  - Toronto\n",
      "  - Vancouver\n",
      "  - Vienna\n",
      "  - Warsaw\n",
      "\n",
      "============================================================\n",
      "PIPELINE COMPLETE!\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Sentinel-2 Multi-Month Data Preprocessing Pipeline\n",
    "Processes Sentinel-2 data for multiple cities and creates multi-temporal stacks\n",
    "\"\"\"\n",
    "\n",
    "import rasterio\n",
    "import numpy as np\n",
    "import os\n",
    "from pathlib import Path\n",
    "from rasterio.warp import calculate_default_transform, reproject, Resampling\n",
    "from rasterio.merge import merge\n",
    "\n",
    "# ============================================================\n",
    "# CONFIGURATION\n",
    "# ============================================================\n",
    "\n",
    "# Base path to your data\n",
    "BASE_PATH = \"/Users/timgotschim/Documents/LLM/AOI_10m\"\n",
    "\n",
    "# Cities to process\n",
    "CITIES = [\"Sydney\", \"Toronto\", \"Vancouver\", \"Vienna\", \"Warsaw\"]\n",
    "\n",
    "# Month folder patterns (adjust if your naming differs)\n",
    "MONTHS = {\n",
    "    \"April\": \"APR_R10m\",\n",
    "    \"August\": \"AUG_10m\", \n",
    "    \"November\": \"NOV_10m\"\n",
    "}\n",
    "\n",
    "# Sentinel-2 10m resolution bands\n",
    "BANDS_10M = [\"B02\", \"B03\", \"B04\", \"B08\"]  # Blue, Green, Red, NIR\n",
    "\n",
    "# Output folder\n",
    "OUTPUT_FOLDER = \"processed_stacks\"\n",
    "os.makedirs(OUTPUT_FOLDER, exist_ok=True)\n",
    "\n",
    "# ============================================================\n",
    "# HELPER FUNCTIONS\n",
    "# ============================================================\n",
    "\n",
    "def find_band_file(folder_path, band_name):\n",
    "    \"\"\"\n",
    "    Find the .jp2 file for a specific band in the Sentinel-2 folder structure.\n",
    "    Handles both SAFE format and extracted flat structure.\n",
    "    \"\"\"\n",
    "    folder = Path(folder_path)\n",
    "    \n",
    "    # Check if folder exists\n",
    "    if not folder.exists():\n",
    "        print(f\"      ERROR: Folder does not exist: {folder}\")\n",
    "        return None\n",
    "    \n",
    "    # Common patterns for Sentinel-2 files\n",
    "    patterns = [\n",
    "        f\"*_{band_name}_10m.jp2\",     # Your format: T56HLH_20250419T235311_B02_10m.jp2\n",
    "        f\"*_{band_name}.jp2\",         # Without _10m suffix\n",
    "        f\"**/*_{band_name}_10m.jp2\",  # Standard naming with subdirs\n",
    "        f\"**/*_{band_name}.jp2\",\n",
    "        f\"**/IMG_DATA/**/*{band_name}*.jp2\"\n",
    "    ]\n",
    "    \n",
    "    for pattern in patterns:\n",
    "        matches = list(folder.glob(pattern))\n",
    "        if matches:\n",
    "            print(f\"      ✓ Found {band_name}: {matches[0].name}\")\n",
    "            return str(matches[0])\n",
    "    \n",
    "    # If not found, try to find ANY file with the band name\n",
    "    all_jp2_files = list(folder.rglob(\"*.jp2\"))\n",
    "    for file in all_jp2_files:\n",
    "        if band_name in file.name:\n",
    "            print(f\"      ✓ Found {band_name} (fuzzy match): {file.name}\")\n",
    "            return str(file)\n",
    "    \n",
    "    # Debug: Show what files are actually in the folder\n",
    "    print(f\"      ✗ Could not find {band_name}\")\n",
    "    print(f\"      DEBUG: Listing .jp2 files in {folder.name}:\")\n",
    "    if all_jp2_files:\n",
    "        for f in all_jp2_files[:8]:  # Show first 8 files\n",
    "            print(f\"        - {f.name}\")\n",
    "        if len(all_jp2_files) > 8:\n",
    "            print(f\"        ... and {len(all_jp2_files) - 8} more files\")\n",
    "    else:\n",
    "        print(f\"        - No .jp2 files found in {folder} or subdirectories!\")\n",
    "        # Check if folder is empty\n",
    "        all_files = list(folder.rglob(\"*\"))\n",
    "        print(f\"        - Total files/folders: {len(all_files)}\")\n",
    "    \n",
    "    return None\n",
    "\n",
    "\n",
    "def load_and_stack_bands(folder_path, bands):\n",
    "    \"\"\"\n",
    "    Load multiple bands from a Sentinel-2 folder and stack them.\n",
    "    Returns: numpy array (bands, height, width), metadata\n",
    "    \"\"\"\n",
    "    band_arrays = []\n",
    "    profile = None\n",
    "    \n",
    "    print(f\"  Loading bands from: {Path(folder_path).name}\")\n",
    "    \n",
    "    for band in bands:\n",
    "        band_file = find_band_file(folder_path, band)\n",
    "        \n",
    "        if band_file is None:\n",
    "            print(f\"    WARNING: {band} not found, skipping...\")\n",
    "            continue\n",
    "            \n",
    "        print(f\"    ✓ Loading {band}: {Path(band_file).name}\")\n",
    "        \n",
    "        with rasterio.open(band_file) as src:\n",
    "            band_data = src.read(1)\n",
    "            band_arrays.append(band_data)\n",
    "            \n",
    "            # Store metadata from first band\n",
    "            if profile is None:\n",
    "                profile = src.profile.copy()\n",
    "    \n",
    "    if not band_arrays:\n",
    "        return None, None\n",
    "    \n",
    "    # Stack all bands\n",
    "    stacked = np.stack(band_arrays, axis=0)\n",
    "    \n",
    "    # Update profile for multi-band\n",
    "    # Use uint16 for compatibility (Sentinel-2 native format)\n",
    "    profile.update(\n",
    "        count=len(band_arrays), \n",
    "        dtype='uint16',\n",
    "        driver='GTiff',  # Use GeoTIFF instead of JP2\n",
    "        compress='lzw'   # Add compression to save space\n",
    "    )\n",
    "    \n",
    "    return stacked, profile\n",
    "\n",
    "\n",
    "def create_multimonth_stack(city, base_path, months, bands):\n",
    "    \"\"\"\n",
    "    Create a multi-month stack for a city by loading data from all months.\n",
    "    \"\"\"\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"PROCESSING CITY: {city}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    all_month_data = []\n",
    "    final_profile = None\n",
    "    \n",
    "    for month_name, month_suffix in months.items():\n",
    "        folder_path = f\"{base_path}/{city}_{month_suffix}\"\n",
    "        \n",
    "        print(f\"\\n=== Processing {city} - {month_name} ===\")\n",
    "        \n",
    "        # Check if folder exists\n",
    "        if not os.path.exists(folder_path):\n",
    "            print(f\"  WARNING: Folder not found: {folder_path}\")\n",
    "            print(f\"  Skipping {month_name} for {city}...\")\n",
    "            continue\n",
    "        \n",
    "        # Load bands for this month\n",
    "        month_stack, profile = load_and_stack_bands(folder_path, bands)\n",
    "        \n",
    "        if month_stack is None:\n",
    "            print(f\"  WARNING: No bands loaded for {month_name}, skipping...\")\n",
    "            continue\n",
    "        \n",
    "        print(f\"  ✓ Loaded {month_stack.shape[0]} bands, shape: {month_stack.shape}\")\n",
    "        \n",
    "        all_month_data.append(month_stack)\n",
    "        \n",
    "        if final_profile is None:\n",
    "            final_profile = profile\n",
    "    \n",
    "    # Check if we have data from any month\n",
    "    if not all_month_data:\n",
    "        print(f\"\\n  ERROR: No data loaded for {city}, skipping stack creation\")\n",
    "        return None\n",
    "    \n",
    "    # Concatenate all months along the band dimension\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"CREATING MULTI-MONTH STACK\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    full_stack = np.concatenate(all_month_data, axis=0)\n",
    "    \n",
    "    # Convert to uint16 if necessary (Sentinel-2 native format)\n",
    "    if full_stack.dtype != np.uint16:\n",
    "        print(f\"  Converting from {full_stack.dtype} to uint16...\")\n",
    "        full_stack = full_stack.astype(np.uint16)\n",
    "    \n",
    "    print(f\"  Final stack shape: {full_stack.shape}\")\n",
    "    print(f\"  Total bands: {full_stack.shape[0]} ({len(all_month_data)} months × {len(bands)} bands)\")\n",
    "    \n",
    "    # Update profile\n",
    "    final_profile.update(\n",
    "        count=full_stack.shape[0],\n",
    "        dtype='uint16'\n",
    "    )\n",
    "    \n",
    "    # Save the stack\n",
    "    output_path = f\"{OUTPUT_FOLDER}/{city}_MultiMonth_stack.tif\"\n",
    "    \n",
    "    print(f\"\\n  Saving to: {output_path}\")\n",
    "    \n",
    "    with rasterio.open(output_path, 'w', **final_profile) as dst:\n",
    "        dst.write(full_stack)\n",
    "    \n",
    "    print(f\"  ✓ Stack saved successfully!\")\n",
    "    \n",
    "    # Print summary statistics\n",
    "    print(f\"\\n  Stack Statistics:\")\n",
    "    print(f\"    Min: {np.nanmin(full_stack):.2f}\")\n",
    "    print(f\"    Max: {np.nanmax(full_stack):.2f}\")\n",
    "    print(f\"    Mean: {np.nanmean(full_stack):.2f}\")\n",
    "    print(f\"    NaN pixels: {np.isnan(full_stack).sum():,}\")\n",
    "    \n",
    "    return output_path\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# MAIN PROCESSING LOOP\n",
    "# ============================================================\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Process all cities and create multi-month stacks.\n",
    "    \"\"\"\n",
    "    print(\"=\"*60)\n",
    "    print(\"SENTINEL-2 MULTI-MONTH PREPROCESSING PIPELINE\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"\\nBase path: {BASE_PATH}\")\n",
    "    print(f\"Cities: {', '.join(CITIES)}\")\n",
    "    print(f\"Months: {', '.join(MONTHS.keys())}\")\n",
    "    print(f\"Bands: {', '.join(BANDS_10M)}\")\n",
    "    print(f\"Output folder: {OUTPUT_FOLDER}\")\n",
    "    \n",
    "    successful_cities = []\n",
    "    failed_cities = []\n",
    "    \n",
    "    for city in CITIES:\n",
    "        try:\n",
    "            output_path = create_multimonth_stack(\n",
    "                city=city,\n",
    "                base_path=BASE_PATH,\n",
    "                months=MONTHS,\n",
    "                bands=BANDS_10M\n",
    "            )\n",
    "            \n",
    "            if output_path:\n",
    "                successful_cities.append(city)\n",
    "            else:\n",
    "                failed_cities.append(city)\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"\\n  ERROR processing {city}: {str(e)}\")\n",
    "            failed_cities.append(city)\n",
    "    \n",
    "    # Final summary\n",
    "    print(f\"\\n\\n{'='*60}\")\n",
    "    print(\"PROCESSING SUMMARY\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"\\n✓ Successfully processed: {len(successful_cities)} cities\")\n",
    "    for city in successful_cities:\n",
    "        print(f\"  - {city}\")\n",
    "    \n",
    "    if failed_cities:\n",
    "        print(f\"\\n✗ Failed: {len(failed_cities)} cities\")\n",
    "        for city in failed_cities:\n",
    "            print(f\"  - {city}\")\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"PIPELINE COMPLETE!\")\n",
    "    print(f\"{'='*60}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9dae1175",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "PROCESSING: Sydney\n",
      "============================================================\n",
      "Loaded AOI for Sydney\n",
      "Fetching OSM green areas...\n",
      "✓ Saved: sentinel_data/Sydney/Sydney_OSM_green.geojson\n",
      "  Features: 1458\n",
      "  Total area: 7.75 km²\n",
      "\n",
      "============================================================\n",
      "ALL CITIES PROCESSED!\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "import osmnx as ox\n",
    "import geopandas as gpd\n",
    "import os\n",
    "\n",
    "# ------------------------------\n",
    "# Configuration\n",
    "# ------------------------------\n",
    "aoi_base_folder = \"aois_json\"\n",
    "output_base_folder = \"sentinel_data\"\n",
    "cities = [\"Sydney\"]\n",
    "\n",
    "# Define tags for green areas\n",
    "tags = {\n",
    "    \"leisure\": [\"park\", \"garden\"],\n",
    "    \"landuse\": [\"forest\", \"grass\", \"meadow\", \"village_green\"],\n",
    "    \"natural\": [\"wood\", \"scrub\"]\n",
    "}\n",
    "\n",
    "# ------------------------------\n",
    "# Process each city\n",
    "# ------------------------------\n",
    "for city in cities:\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"PROCESSING: {city}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # Define paths\n",
    "    aoi_file = os.path.join(aoi_base_folder, f\"{city}.geojson\")\n",
    "    output_file = os.path.join(output_base_folder, city, f\"{city}_OSM_green.geojson\")\n",
    "    \n",
    "    # Check if AOI file exists\n",
    "    if not os.path.exists(aoi_file):\n",
    "        print(f\"WARNING: AOI file not found: {aoi_file}\")\n",
    "        print(f\"Skipping {city}...\")\n",
    "        continue\n",
    "    \n",
    "    try:\n",
    "        # Load AOI\n",
    "        aoi = gpd.read_file(aoi_file)\n",
    "        aoi = aoi.to_crs(\"EPSG:4326\")  # ensure WGS84\n",
    "        polygon = aoi.geometry.iloc[0]  # get shapely polygon\n",
    "        \n",
    "        print(f\"Loaded AOI for {city}\")\n",
    "        \n",
    "        # Fetch green features from OSM\n",
    "        print(f\"Fetching OSM green areas...\")\n",
    "        green_features = ox.features_from_polygon(polygon, tags)\n",
    "        \n",
    "        # Keep only polygons\n",
    "        green_features = green_features[green_features.geometry.type.isin([\"Polygon\", \"MultiPolygon\"])]\n",
    "        \n",
    "        if len(green_features) == 0:\n",
    "            print(f\"WARNING: No green area polygons found for {city}\")\n",
    "            continue\n",
    "        \n",
    "        # Calculate total area\n",
    "        total_area_km2 = green_features.to_crs('EPSG:3857').area.sum() / 1e6\n",
    "        \n",
    "        # Save to GeoJSON\n",
    "        os.makedirs(os.path.dirname(output_file), exist_ok=True)\n",
    "        green_features.to_file(output_file, driver=\"GeoJSON\")\n",
    "        \n",
    "        print(f\"✓ Saved: {output_file}\")\n",
    "        print(f\"  Features: {len(green_features)}\")\n",
    "        print(f\"  Total area: {total_area_km2:.2f} km²\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"ERROR processing {city}: {str(e)}\")\n",
    "        continue\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"ALL CITIES PROCESSED!\")\n",
    "print(f\"{'='*60}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9a181ac0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "PROCESSING: Sydney\n",
      "============================================================\n",
      "Loaded stack metadata: 10980x10980 pixels\n",
      "Loaded 1458 green area polygons\n",
      "Rasterizing green areas...\n",
      "  Completed: 58100/120560400 pixels labeled as green (0.05%)\n",
      "✓ Saved: sentinel_data/Sydney/Sydney_OSM_labels.tif\n",
      "\n",
      "============================================================\n",
      "ALL CITIES PROCESSED!\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "import rasterio\n",
    "from rasterio.features import rasterize\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# ------------------------------\n",
    "# Configuration\n",
    "# ------------------------------\n",
    "sentinel_base_folder = \"sentinel_data\"\n",
    "stack_folder = \"processed_stacks\"        \n",
    "cities = [\"Sydney\"]\n",
    "\n",
    "# ------------------------------\n",
    "# Process each city\n",
    "# ------------------------------\n",
    "for city in cities:\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"PROCESSING: {city}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # Define paths\n",
    "    stack_path = os.path.join(stack_folder, f\"{city}_MultiMonth_stack.tif\")\n",
    "    osm_path = os.path.join(sentinel_base_folder, city, f\"{city}_OSM_green.geojson\")\n",
    "    label_path = os.path.join(sentinel_base_folder, city, f\"{city}_OSM_labels.tif\")\n",
    "    \n",
    "    # Check if required files exist\n",
    "    if not os.path.exists(stack_path):\n",
    "        print(f\"WARNING: Stack file not found: {stack_path}\")\n",
    "        print(f\"Skipping {city}...\")\n",
    "        continue\n",
    "    \n",
    "    if not os.path.exists(osm_path):\n",
    "        print(f\"WARNING: OSM green file not found: {osm_path}\")\n",
    "        print(f\"Skipping {city}...\")\n",
    "        continue\n",
    "    \n",
    "    try:\n",
    "        # Load Sentinel-2 stack metadata\n",
    "        with rasterio.open(stack_path) as src:\n",
    "            transform = src.transform\n",
    "            out_shape = (src.height, src.width)\n",
    "            crs = src.crs\n",
    "        \n",
    "        print(f\"Loaded stack metadata: {out_shape[0]}x{out_shape[1]} pixels\")\n",
    "        \n",
    "        # Load GeoJSON of green areas from OSM\n",
    "        green_features = gpd.read_file(osm_path)\n",
    "        \n",
    "        # Ensure CRS matches Sentinel-2\n",
    "        green_features = green_features.to_crs(crs)\n",
    "        \n",
    "        # Keep only polygons\n",
    "        green_features = green_features[green_features.geometry.type.isin([\"Polygon\", \"MultiPolygon\"])]\n",
    "        \n",
    "        if len(green_features) == 0:\n",
    "            print(f\"WARNING: No polygon features found for {city}\")\n",
    "            continue\n",
    "        \n",
    "        print(f\"Loaded {len(green_features)} green area polygons\")\n",
    "        \n",
    "        # ------------------------------\n",
    "        # Rasterize with all_touched approach\n",
    "        # ------------------------------\n",
    "        print(\"Rasterizing green areas...\")\n",
    "        \n",
    "        labels = rasterize(\n",
    "            [(geom, 1) for geom in green_features.geometry],\n",
    "            out_shape=out_shape,\n",
    "            transform=transform,\n",
    "            fill=0,\n",
    "            all_touched=True,   # include pixels partially covered\n",
    "            dtype=\"uint8\"\n",
    "        )\n",
    "        \n",
    "        green_count = np.sum(labels == 1)\n",
    "        total_pixels = labels.size\n",
    "        print(f\"  Completed: {green_count}/{total_pixels} pixels labeled as green ({100*green_count/total_pixels:.2f}%)\")\n",
    "        \n",
    "        # ------------------------------\n",
    "        # Save raster labels\n",
    "        # ------------------------------\n",
    "        with rasterio.open(\n",
    "            label_path,\n",
    "            \"w\",\n",
    "            driver=\"GTiff\",\n",
    "            height=out_shape[0],\n",
    "            width=out_shape[1],\n",
    "            count=1,\n",
    "            dtype=\"uint8\",\n",
    "            crs=crs,\n",
    "            transform=transform,\n",
    "            compress=\"lzw\"  # Add compression to reduce file size\n",
    "        ) as dst:\n",
    "            dst.write(labels, 1)\n",
    "        \n",
    "        print(f\"✓ Saved: {label_path}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"ERROR processing {city}: {str(e)}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        continue\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"ALL CITIES PROCESSED!\")\n",
    "print(f\"{'='*60}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a305689b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "RANDOM FOREST TRAINING - Sydney\n",
      "============================================================\n",
      "\n",
      "Results will be saved to: /Users/timgotschim/Documents/LLM/infrared.city/results/Sydney_20251125_181335\n",
      "\n",
      "============================================================\n",
      "LOADING DATA\n",
      "============================================================\n",
      "✓ Loaded Sentinel-2 stack: (12, 10980, 10980)\n",
      "✓ Loaded labels: (10980, 10980)\n",
      "\n",
      "============================================================\n",
      "PREPARING DATA\n",
      "============================================================\n",
      "Original shape: 10980 × 10980 = 120,560,400 pixels\n",
      "After removing NaN: 120,560,400 pixels\n",
      "\n",
      "============================================================\n",
      "CLASS DISTRIBUTION\n",
      "============================================================\n",
      "Class 0: 120,502,300 samples (99.95%)\n",
      "Class 1: 58,100 samples (0.05%)\n",
      "\n",
      "Imbalance ratio: 2074.0:1 (non-green:green)\n",
      "\n",
      "============================================================\n",
      "TRAIN-TEST SPLIT\n",
      "============================================================\n",
      "Train set: 96,448,320 samples\n",
      "  Green: 46,480 (0.05%)\n",
      "Test set: 24,112,080 samples\n",
      "  Green: 11,620 (0.05%)\n",
      "\n",
      "============================================================\n",
      "TRAINING RANDOM FOREST\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 8 concurrent workers.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Random Forest Training with Results Export\n",
    "Trains model on Sentinel-2 data and saves all results to disk\n",
    "\"\"\"\n",
    "\n",
    "import rasterio\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, balanced_accuracy_score, f1_score\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ============================================================\n",
    "# CONFIGURATION\n",
    "# ============================================================\n",
    "\n",
    "# Input paths\n",
    "SENTINEL_BASE = \"processed_stacks\"\n",
    "CITY = \"Sydney\"  # Change this for other cities\n",
    "\n",
    "# Output paths\n",
    "OUTPUT_BASE = \"/Users/timgotschim/Documents/LLM/infrared.city/results\"\n",
    "os.makedirs(OUTPUT_BASE, exist_ok=True)\n",
    "\n",
    "# Create timestamped folder for this run\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "run_folder = os.path.join(OUTPUT_BASE, f\"{CITY}_{timestamp}\")\n",
    "os.makedirs(run_folder, exist_ok=True)\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(f\"RANDOM FOREST TRAINING - {CITY}\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nResults will be saved to: {run_folder}\\n\")\n",
    "\n",
    "# ============================================================\n",
    "# 1. LOAD DATA\n",
    "# ============================================================\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"LOADING DATA\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "stack_path = os.path.join(SENTINEL_BASE, f\"{CITY}_MultiMonth_stack.tif\")\n",
    "labels_path = f\"sentinel_data/{CITY}/{CITY}_OSM_labels.tif\"\n",
    "\n",
    "# Load Sentinel-2 stack\n",
    "with rasterio.open(stack_path) as src:\n",
    "    X = src.read()  # shape: (bands, height, width)\n",
    "    profile = src.profile.copy()\n",
    "    transform = src.transform\n",
    "\n",
    "print(f\"✓ Loaded Sentinel-2 stack: {X.shape}\")\n",
    "\n",
    "# Load labels\n",
    "with rasterio.open(labels_path) as src:\n",
    "    y = src.read(1)  # shape: (height, width)\n",
    "\n",
    "print(f\"✓ Loaded labels: {y.shape}\")\n",
    "\n",
    "# ============================================================\n",
    "# 2. PREPARE DATA\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"PREPARING DATA\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Flatten to (n_samples, n_features)\n",
    "n_bands, h, w = X.shape\n",
    "X_flat = X.reshape(n_bands, -1).T  # shape: (h*w, n_bands)\n",
    "y_flat = y.flatten()                # shape: (h*w,)\n",
    "\n",
    "print(f\"Original shape: {h} × {w} = {h*w:,} pixels\")\n",
    "\n",
    "# Remove NaN values\n",
    "mask = ~np.isnan(X_flat).any(axis=1)\n",
    "X_flat = X_flat[mask]\n",
    "y_flat = y_flat[mask]\n",
    "\n",
    "print(f\"After removing NaN: {len(y_flat):,} pixels\")\n",
    "\n",
    "# ============================================================\n",
    "# 3. CLASS DISTRIBUTION ANALYSIS\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"CLASS DISTRIBUTION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "unique, counts = np.unique(y_flat, return_counts=True)\n",
    "total = len(y_flat)\n",
    "\n",
    "class_distribution = {}\n",
    "for label, count in zip(unique, counts):\n",
    "    percentage = 100*count/total\n",
    "    class_distribution[f\"Class_{int(label)}\"] = {\n",
    "        \"count\": int(count),\n",
    "        \"percentage\": round(percentage, 2)\n",
    "    }\n",
    "    print(f\"Class {int(label)}: {count:,} samples ({percentage:.2f}%)\")\n",
    "\n",
    "if len(counts) == 2:\n",
    "    imbalance_ratio = counts[0]/counts[1]\n",
    "    print(f\"\\nImbalance ratio: {imbalance_ratio:.1f}:1 (non-green:green)\")\n",
    "    class_distribution[\"imbalance_ratio\"] = round(imbalance_ratio, 2)\n",
    "\n",
    "# ============================================================\n",
    "# 4. TRAIN-TEST SPLIT\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"TRAIN-TEST SPLIT\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_flat, y_flat, \n",
    "    test_size=0.2, \n",
    "    random_state=42,\n",
    "    stratify=y_flat\n",
    ")\n",
    "\n",
    "split_info = {\n",
    "    \"train_samples\": int(len(y_train)),\n",
    "    \"test_samples\": int(len(y_test)),\n",
    "    \"train_green\": int(np.sum(y_train==1)),\n",
    "    \"train_green_pct\": round(100*np.mean(y_train==1), 2),\n",
    "    \"test_green\": int(np.sum(y_test==1)),\n",
    "    \"test_green_pct\": round(100*np.mean(y_test==1), 2)\n",
    "}\n",
    "\n",
    "print(f\"Train set: {split_info['train_samples']:,} samples\")\n",
    "print(f\"  Green: {split_info['train_green']:,} ({split_info['train_green_pct']:.2f}%)\")\n",
    "print(f\"Test set: {split_info['test_samples']:,} samples\")\n",
    "print(f\"  Green: {split_info['test_green']:,} ({split_info['test_green_pct']:.2f}%)\")\n",
    "\n",
    "# ============================================================\n",
    "# 5. TRAIN RANDOM FOREST\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"TRAINING RANDOM FOREST\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "clf = RandomForestClassifier(\n",
    "    n_estimators=200,\n",
    "    max_depth=25,\n",
    "    min_samples_split=10,\n",
    "    min_samples_leaf=5,\n",
    "    class_weight=\"balanced\",\n",
    "    n_jobs=-1,\n",
    "    random_state=42,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "print(\"\\n✓ Training complete!\")\n",
    "\n",
    "# ============================================================\n",
    "# 6. EVALUATION\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"EVALUATION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "report_dict = classification_report(y_test, y_pred, target_names=[\"Non-green\", \"Green\"], output_dict=True)\n",
    "print(classification_report(y_test, y_pred, target_names=[\"Non-green\", \"Green\"]))\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(\"                Predicted\")\n",
    "print(\"              Non-green  Green\")\n",
    "print(f\"Actual Non-g  {cm[0,0]:8d}  {cm[0,1]:6d}\")\n",
    "print(f\"       Green  {cm[1,0]:8d}  {cm[1,1]:6d}\")\n",
    "\n",
    "# Additional metrics\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "metrics = {\n",
    "    \"balanced_accuracy\": round(balanced_accuracy_score(y_test, y_pred), 3),\n",
    "    \"f1_green\": round(f1_score(y_test, y_pred, pos_label=1), 3),\n",
    "    \"f1_macro\": round(f1_score(y_test, y_pred, average='macro'), 3),\n",
    "    \"sensitivity\": round(tp / (tp + fn), 3),\n",
    "    \"specificity\": round(tn / (tn + fp), 3),\n",
    "    \"precision_green\": round(report_dict['Green']['precision'], 3),\n",
    "    \"recall_green\": round(report_dict['Green']['recall'], 3)\n",
    "}\n",
    "\n",
    "print(\"\\n\" + \"-\"*60)\n",
    "print(\"SUMMARY METRICS:\")\n",
    "print(\"-\"*60)\n",
    "for key, value in metrics.items():\n",
    "    print(f\"{key:20s}: {value:.3f}\")\n",
    "\n",
    "# ============================================================\n",
    "# 7. FEATURE IMPORTANCE\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"BAND IMPORTANCE\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Generate band names\n",
    "months = ['April', 'August', 'November']\n",
    "bands = ['B02', 'B03', 'B04', 'B08']\n",
    "band_names = [f\"{month}_{band}\" for month in months for band in bands]\n",
    "\n",
    "feature_importance = pd.DataFrame({\n",
    "    'band': band_names,\n",
    "    'importance': clf.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(\"\\nTop 10 Most Important Bands:\")\n",
    "for idx, row in feature_importance.head(10).iterrows():\n",
    "    print(f\"{row['band']:20s}: {row['importance']:.4f}\")\n",
    "\n",
    "# ============================================================\n",
    "# 8. CREATE PREDICTION MAP\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"CREATING PREDICTION MAP\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Predict on full image\n",
    "X_full_flat = X.reshape(n_bands, -1).T\n",
    "mask_full = ~np.isnan(X_full_flat).any(axis=1)\n",
    "\n",
    "y_pred_full = np.zeros(X_full_flat.shape[0])\n",
    "y_pred_full[mask_full] = clf.predict(X_full_flat[mask_full])\n",
    "y_pred_map = y_pred_full.reshape(h, w)\n",
    "\n",
    "print(\"✓ Prediction map created\")\n",
    "\n",
    "# ============================================================\n",
    "# 9. SAVE ALL RESULTS\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"SAVING RESULTS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# 9.1 Save metadata as JSON\n",
    "metadata = {\n",
    "    \"city\": CITY,\n",
    "    \"timestamp\": timestamp,\n",
    "    \"image_shape\": {\"height\": h, \"width\": w, \"bands\": n_bands},\n",
    "    \"class_distribution\": class_distribution,\n",
    "    \"split_info\": split_info,\n",
    "    \"metrics\": metrics,\n",
    "    \"model_params\": {\n",
    "        \"n_estimators\": 200,\n",
    "        \"max_depth\": 25,\n",
    "        \"min_samples_split\": 10,\n",
    "        \"min_samples_leaf\": 5,\n",
    "        \"class_weight\": \"balanced\"\n",
    "    }\n",
    "}\n",
    "\n",
    "with open(os.path.join(run_folder, \"metadata.json\"), \"w\") as f:\n",
    "    json.dump(metadata, f, indent=2)\n",
    "print(\"✓ Saved metadata.json\")\n",
    "\n",
    "# 9.2 Save classification report as CSV\n",
    "report_df = pd.DataFrame(report_dict).transpose()\n",
    "report_df.to_csv(os.path.join(run_folder, \"classification_report.csv\"))\n",
    "print(\"✓ Saved classification_report.csv\")\n",
    "\n",
    "# 9.3 Save feature importance as CSV\n",
    "feature_importance.to_csv(os.path.join(run_folder, \"feature_importance.csv\"), index=False)\n",
    "print(\"✓ Saved feature_importance.csv\")\n",
    "\n",
    "# 9.4 Save confusion matrix as CSV\n",
    "cm_df = pd.DataFrame(cm, \n",
    "                     index=['Actual_Non-green', 'Actual_Green'],\n",
    "                     columns=['Predicted_Non-green', 'Predicted_Green'])\n",
    "cm_df.to_csv(os.path.join(run_folder, \"confusion_matrix.csv\"))\n",
    "print(\"✓ Saved confusion_matrix.csv\")\n",
    "\n",
    "# 9.5 Save prediction map as GeoTIFF\n",
    "pred_profile = profile.copy()\n",
    "pred_profile.update(dtype='uint8', count=1, compress='lzw')\n",
    "\n",
    "with rasterio.open(os.path.join(run_folder, \"prediction_map.tif\"), 'w', **pred_profile) as dst:\n",
    "    dst.write(y_pred_map.astype(np.uint8), 1)\n",
    "print(\"✓ Saved prediction_map.tif\")\n",
    "\n",
    "# 9.6 Save ground truth for comparison\n",
    "with rasterio.open(os.path.join(run_folder, \"ground_truth.tif\"), 'w', **pred_profile) as dst:\n",
    "    dst.write(y.astype(np.uint8), 1)\n",
    "print(\"✓ Saved ground_truth.tif\")\n",
    "\n",
    "# ============================================================\n",
    "# 10. CREATE VISUALIZATIONS\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"CREATING VISUALIZATIONS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# 10.1 Confusion Matrix Heatmap\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "im = ax.imshow(cm, cmap='Blues', aspect='auto')\n",
    "ax.set_xticks([0, 1])\n",
    "ax.set_yticks([0, 1])\n",
    "ax.set_xticklabels(['Non-green', 'Green'])\n",
    "ax.set_yticklabels(['Non-green', 'Green'])\n",
    "ax.set_xlabel('Predicted')\n",
    "ax.set_ylabel('Actual')\n",
    "ax.set_title(f'Confusion Matrix - {CITY}')\n",
    "\n",
    "# Add text annotations\n",
    "for i in range(2):\n",
    "    for j in range(2):\n",
    "        text = ax.text(j, i, f\"{cm[i, j]:,}\", ha=\"center\", va=\"center\", color=\"black\", fontsize=14)\n",
    "\n",
    "plt.colorbar(im, ax=ax)\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(run_folder, \"confusion_matrix.png\"), dpi=300, bbox_inches='tight')\n",
    "plt.close()\n",
    "print(\"✓ Saved confusion_matrix.png\")\n",
    "\n",
    "# 10.2 Feature Importance Bar Chart\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "top_features = feature_importance.head(12)\n",
    "ax.barh(range(len(top_features)), top_features['importance'])\n",
    "ax.set_yticks(range(len(top_features)))\n",
    "ax.set_yticklabels(top_features['band'])\n",
    "ax.set_xlabel('Importance')\n",
    "ax.set_title(f'Top 12 Band Importance - {CITY}')\n",
    "ax.invert_yaxis()\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(run_folder, \"feature_importance.png\"), dpi=300, bbox_inches='tight')\n",
    "plt.close()\n",
    "print(\"✓ Saved feature_importance.png\")\n",
    "\n",
    "# 10.3 Prediction Comparison (RGB + Ground Truth + Prediction)\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "\n",
    "# RGB composite (assuming bands are in order: Apr, Aug, Nov × B02,B03,B04,B08)\n",
    "# Use August bands for visualization (indices 4,5,6 = B02,B03,B04 from August)\n",
    "rgb = X[[6, 5, 4], :, :].transpose(1, 2, 0)  # B04, B03, B02 (Red, Green, Blue)\n",
    "rgb_norm = np.clip(rgb / 3000, 0, 1)  # Normalize for visualization\n",
    "\n",
    "axes[0].imshow(rgb_norm)\n",
    "axes[0].set_title(\"True Color RGB (August)\", fontsize=14)\n",
    "axes[0].axis('off')\n",
    "\n",
    "axes[1].imshow(y, cmap='RdYlGn', vmin=0, vmax=1)\n",
    "axes[1].set_title(\"Ground Truth (OSM)\", fontsize=14)\n",
    "axes[1].axis('off')\n",
    "\n",
    "axes[2].imshow(y_pred_map, cmap='RdYlGn', vmin=0, vmax=1)\n",
    "axes[2].set_title(\"Model Prediction\", fontsize=14)\n",
    "axes[2].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(run_folder, \"prediction_comparison.png\"), dpi=300, bbox_inches='tight')\n",
    "plt.close()\n",
    "print(\"✓ Saved prediction_comparison.png\")\n",
    "\n",
    "# 10.4 Error Map (False Positives & False Negatives)\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "\n",
    "false_positives = (y == 0) & (y_pred_map == 1)\n",
    "false_negatives = (y == 1) & (y_pred_map == 0)\n",
    "\n",
    "axes[0].imshow(rgb_norm)\n",
    "axes[0].set_title(\"RGB Image\", fontsize=14)\n",
    "axes[0].axis('off')\n",
    "\n",
    "axes[1].imshow(false_positives, cmap='Reds', vmin=0, vmax=1)\n",
    "axes[1].set_title(f\"False Positives ({np.sum(false_positives):,} pixels)\", fontsize=14)\n",
    "axes[1].axis('off')\n",
    "\n",
    "axes[2].imshow(false_negatives, cmap='Blues', vmin=0, vmax=1)\n",
    "axes[2].set_title(f\"False Negatives ({np.sum(false_negatives):,} pixels)\", fontsize=14)\n",
    "axes[2].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(run_folder, \"error_analysis.png\"), dpi=300, bbox_inches='tight')\n",
    "plt.close()\n",
    "print(\"✓ Saved error_analysis.png\")\n",
    "\n",
    "# 10.5 Metrics Summary Plot\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "metric_names = list(metrics.keys())\n",
    "metric_values = list(metrics.values())\n",
    "\n",
    "bars = ax.bar(range(len(metric_names)), metric_values, color='steelblue')\n",
    "ax.set_xticks(range(len(metric_names)))\n",
    "ax.set_xticklabels(metric_names, rotation=45, ha='right')\n",
    "ax.set_ylabel('Score')\n",
    "ax.set_title(f'Model Performance Metrics - {CITY}')\n",
    "ax.set_ylim([0, 1])\n",
    "ax.axhline(y=0.8, color='r', linestyle='--', alpha=0.3, label='0.8 threshold')\n",
    "ax.grid(axis='y', alpha=0.3)\n",
    "ax.legend()\n",
    "\n",
    "# Add value labels on bars\n",
    "for i, (bar, value) in enumerate(zip(bars, metric_values)):\n",
    "    ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.02, \n",
    "            f'{value:.3f}', ha='center', va='bottom', fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(run_folder, \"metrics_summary.png\"), dpi=300, bbox_inches='tight')\n",
    "plt.close()\n",
    "print(\"✓ Saved metrics_summary.png\")\n",
    "\n",
    "# ============================================================\n",
    "# 11. CREATE SUMMARY REPORT\n",
    "# ============================================================\n",
    "\n",
    "summary_text = f\"\"\"\n",
    "RANDOM FOREST CLASSIFICATION RESULTS\n",
    "{'='*60}\n",
    "\n",
    "City: {CITY}\n",
    "Date: {timestamp}\n",
    "\n",
    "DATA SUMMARY:\n",
    "- Image size: {h} × {w} pixels\n",
    "- Total bands: {n_bands}\n",
    "- Training samples: {split_info['train_samples']:,}\n",
    "- Test samples: {split_info['test_samples']:,}\n",
    "- Green pixels (test): {split_info['test_green']:,} ({split_info['test_green_pct']:.2f}%)\n",
    "\n",
    "MODEL PERFORMANCE:\n",
    "- Balanced Accuracy: {metrics['balanced_accuracy']:.3f}\n",
    "- F1 Score (Green): {metrics['f1_green']:.3f}\n",
    "- F1 Score (Macro): {metrics['f1_macro']:.3f}\n",
    "- Precision (Green): {metrics['precision_green']:.3f}\n",
    "- Recall/Sensitivity (Green): {metrics['recall_green']:.3f}\n",
    "- Specificity (Non-green): {metrics['specificity']:.3f}\n",
    "\n",
    "CONFUSION MATRIX:\n",
    "                Predicted\n",
    "             Non-green    Green\n",
    "Actual Non-g  {cm[0,0]:8,}  {cm[0,1]:7,}\n",
    "       Green  {cm[1,0]:8,}  {cm[1,1]:7,}\n",
    "\n",
    "TOP 5 MOST IMPORTANT BANDS:\n",
    "\"\"\"\n",
    "\n",
    "for idx, row in feature_importance.head(5).iterrows():\n",
    "    summary_text += f\"  {row['band']:20s}: {row['importance']:.4f}\\n\"\n",
    "\n",
    "summary_text += f\"\"\"\n",
    "FILES SAVED:\n",
    "- metadata.json\n",
    "- classification_report.csv\n",
    "- feature_importance.csv\n",
    "- confusion_matrix.csv\n",
    "- prediction_map.tif\n",
    "- ground_truth.tif\n",
    "- confusion_matrix.png\n",
    "- feature_importance.png\n",
    "- prediction_comparison.png\n",
    "- error_analysis.png\n",
    "- metrics_summary.png\n",
    "\n",
    "Results saved to: {run_folder}\n",
    "\"\"\"\n",
    "\n",
    "with open(os.path.join(run_folder, \"SUMMARY.txt\"), \"w\") as f:\n",
    "    f.write(summary_text)\n",
    "\n",
    "print(\"\\n\" + summary_text)\n",
    "print(\"=\"*60)\n",
    "print(\"✓ ALL RESULTS SAVED SUCCESSFULLY!\")\n",
    "print(\"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
